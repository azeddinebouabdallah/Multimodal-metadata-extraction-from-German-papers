{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f193b50f1d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module): \n",
    "    # This NLP part Will consist of two bidirectional lstm layers and it's output is \n",
    "    # determined by the LSTM's last hidden states or output vectors.\n",
    "\n",
    "    # This will take as an input a sequence of words and output the last hidden layer\n",
    "    # the last hidden states of 2-layer bidirectional LSTM will be the input of the last multimodel network \n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim = 256, layer_dim =2, output_dim = 4):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        #Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim # maybe set this to 256\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building the LSTM \n",
    "        # batch_first = True causes the input/output to be of shape 3D (batch_dim, seq_dim, feature_dim) \n",
    "        # output will be the same dim as the hidden dim\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, layer_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.final_out = nn.Linear(hidden_dim*2, 4)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        # self.layer_dim * 2. because we have one going forwards and another going backwards\n",
    "        h0 = torch.zeros(self.layer_dim * 2, x.size(0), self.hidden_dim)\n",
    "        \n",
    "        \n",
    "        # Initialize cell state\n",
    "        c0 =  torch.zeros(self.layer_dim * 2, x.size(0), self.hidden_dim)\n",
    "\n",
    "        # We suppose we are conducting a 28 time steps In case of using \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm1(x, (h0.detach(), c0.detach()))\n",
    "        \n",
    "        \n",
    "        out = self.final_out(out.view(out.size(0), -1))\n",
    "        \n",
    "        return torch.sigmoid(out)\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 256, 100, 256 if we have (input dim = 100 and hidden dim = 100)\n",
    "        # out[:, -1, :] => 256, 256 --> because we just want the last time step hidden states\n",
    "        #out = out[:, -1, :] # without an activation function\n",
    "\n",
    "        # now our: out.size() --> 256, 10 (if output dimension is equal to 10)\n",
    "        #return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(1041)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 1, 1041])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here i have to get the ELMO vector in a form, in a format of numpy array.\n",
    "with open('document_vector.pickle', 'rb') as file:\n",
    "    vectors = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "vectors = np.delete(vectors, 1, 1)\n",
    "vectors = np.delete(vectors, 0, 1)\n",
    "\n",
    "vectors = torch.from_numpy(np.array(vectors, dtype=np.float64)).view(521, 1, -1).float()\n",
    "vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: title, 2: journal, 3: author, 4: asbtract\n",
    "journal = [1] * 3\n",
    "title = [0] * 10\n",
    "author = [2] * 5\n",
    "abstract = [3] * 503\n",
    "\n",
    "labels =  torch.from_numpy(np.concatenate((journal, title, author, abstract)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3333,  1.0000,  0.0000,  ..., -0.1705,  0.1981, -0.3040]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ..., -0.0636, -0.3796, -0.3931]],\n",
       "\n",
       "        [[ 0.0769,  1.0000,  0.0000,  ..., -0.3025,  0.5232, -0.0270]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2500,  1.0000,  0.0000,  ..., -0.4503,  0.4588,  0.1445]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.2589,  0.4821, -0.0066]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ..., -0.3396,  0.0858,  0.0686]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5099, 0.5014, 0.4987, 0.4826],\n",
      "        [0.5102, 0.5063, 0.4856, 0.5001],\n",
      "        [0.5074, 0.5080, 0.4844, 0.5022],\n",
      "        ...,\n",
      "        [0.5067, 0.5110, 0.4854, 0.5016],\n",
      "        [0.5068, 0.5101, 0.4861, 0.5015],\n",
      "        [0.5085, 0.5071, 0.4955, 0.4968]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5101, 0.5016, 0.4988, 0.4939],\n",
      "        [0.5111, 0.5064, 0.4855, 0.5144],\n",
      "        [0.5084, 0.5083, 0.4844, 0.5168],\n",
      "        ...,\n",
      "        [0.5079, 0.5114, 0.4853, 0.5153],\n",
      "        [0.5075, 0.5112, 0.4861, 0.5148],\n",
      "        [0.5092, 0.5068, 0.4958, 0.5096]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5104, 0.5017, 0.4989, 0.5051],\n",
      "        [0.5120, 0.5064, 0.4855, 0.5286],\n",
      "        [0.5094, 0.5085, 0.4845, 0.5315],\n",
      "        ...,\n",
      "        [0.5089, 0.5122, 0.4849, 0.5291],\n",
      "        [0.5084, 0.5122, 0.4859, 0.5284],\n",
      "        [0.5099, 0.5061, 0.4957, 0.5225]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5106, 0.5019, 0.4989, 0.5164],\n",
      "        [0.5129, 0.5066, 0.4855, 0.5429],\n",
      "        [0.5104, 0.5088, 0.4845, 0.5462],\n",
      "        ...,\n",
      "        [0.5103, 0.5136, 0.4837, 0.5439],\n",
      "        [0.5097, 0.5139, 0.4848, 0.5433],\n",
      "        [0.5105, 0.5055, 0.4957, 0.5355]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5110, 0.5021, 0.4990, 0.5277],\n",
      "        [0.5138, 0.5067, 0.4856, 0.5572],\n",
      "        [0.5115, 0.5090, 0.4845, 0.5610],\n",
      "        ...,\n",
      "        [0.5111, 0.5140, 0.4838, 0.5577],\n",
      "        [0.5105, 0.5146, 0.4848, 0.5571],\n",
      "        [0.5112, 0.5054, 0.4959, 0.5482]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5113, 0.5023, 0.4990, 0.5390],\n",
      "        [0.5147, 0.5068, 0.4856, 0.5716],\n",
      "        [0.5126, 0.5092, 0.4846, 0.5759],\n",
      "        ...,\n",
      "        [0.5118, 0.5143, 0.4841, 0.5714],\n",
      "        [0.5114, 0.5149, 0.4853, 0.5709],\n",
      "        [0.5120, 0.5056, 0.4961, 0.5610]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5117, 0.5026, 0.4989, 0.5505],\n",
      "        [0.5156, 0.5069, 0.4857, 0.5861],\n",
      "        [0.5137, 0.5094, 0.4846, 0.5907],\n",
      "        ...,\n",
      "        [0.5141, 0.5144, 0.4849, 0.5863],\n",
      "        [0.5151, 0.5151, 0.4866, 0.5869],\n",
      "        [0.5136, 0.5068, 0.4954, 0.5751]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5121, 0.5029, 0.4989, 0.5620],\n",
      "        [0.5165, 0.5071, 0.4857, 0.6006],\n",
      "        [0.5148, 0.5096, 0.4847, 0.6055],\n",
      "        ...,\n",
      "        [0.5171, 0.5144, 0.4860, 0.6018],\n",
      "        [0.5165, 0.5152, 0.4871, 0.6015],\n",
      "        [0.5152, 0.5079, 0.4946, 0.5895]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5126, 0.5033, 0.4988, 0.5736],\n",
      "        [0.5174, 0.5073, 0.4857, 0.6151],\n",
      "        [0.5158, 0.5098, 0.4848, 0.6202],\n",
      "        ...,\n",
      "        [0.5175, 0.5145, 0.4861, 0.6158],\n",
      "        [0.5170, 0.5153, 0.4872, 0.6156],\n",
      "        [0.5166, 0.5083, 0.4944, 0.6042]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5132, 0.5037, 0.4986, 0.5854],\n",
      "        [0.5183, 0.5075, 0.4858, 0.6296],\n",
      "        [0.5168, 0.5100, 0.4849, 0.6349],\n",
      "        ...,\n",
      "        [0.5180, 0.5146, 0.4863, 0.6300],\n",
      "        [0.5174, 0.5154, 0.4874, 0.6298],\n",
      "        [0.5179, 0.5085, 0.4941, 0.6183]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5139, 0.5042, 0.4985, 0.5973],\n",
      "        [0.5193, 0.5077, 0.4858, 0.6442],\n",
      "        [0.5178, 0.5102, 0.4851, 0.6495],\n",
      "        ...,\n",
      "        [0.5194, 0.5142, 0.4872, 0.6463],\n",
      "        [0.5188, 0.5150, 0.4884, 0.6463],\n",
      "        [0.5203, 0.5082, 0.4926, 0.6327]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5147, 0.5048, 0.4983, 0.6094],\n",
      "        [0.5203, 0.5079, 0.4857, 0.6588],\n",
      "        [0.5188, 0.5104, 0.4852, 0.6639],\n",
      "        ...,\n",
      "        [0.5195, 0.5148, 0.4874, 0.6604],\n",
      "        [0.5189, 0.5155, 0.4887, 0.6607],\n",
      "        [0.5233, 0.5078, 0.4904, 0.6476]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5155, 0.5054, 0.4980, 0.6217],\n",
      "        [0.5212, 0.5082, 0.4857, 0.6733],\n",
      "        [0.5198, 0.5107, 0.4854, 0.6782],\n",
      "        ...,\n",
      "        [0.5191, 0.5167, 0.4871, 0.6748],\n",
      "        [0.5186, 0.5169, 0.4885, 0.6750],\n",
      "        [0.5261, 0.5071, 0.4889, 0.6636]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5165, 0.5061, 0.4978, 0.6343],\n",
      "        [0.5223, 0.5084, 0.4856, 0.6877],\n",
      "        [0.5208, 0.5109, 0.4856, 0.6924],\n",
      "        ...,\n",
      "        [0.5207, 0.5176, 0.4857, 0.6919],\n",
      "        [0.5198, 0.5183, 0.4871, 0.6920],\n",
      "        [0.5285, 0.5072, 0.4864, 0.6790]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5175, 0.5069, 0.4975, 0.6470],\n",
      "        [0.5234, 0.5086, 0.4856, 0.7020],\n",
      "        [0.5219, 0.5111, 0.4857, 0.7064],\n",
      "        ...,\n",
      "        [0.5217, 0.5177, 0.4854, 0.7060],\n",
      "        [0.5210, 0.5186, 0.4867, 0.7065],\n",
      "        [0.5300, 0.5072, 0.4860, 0.6940]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5186, 0.5077, 0.4973, 0.6600],\n",
      "        [0.5245, 0.5089, 0.4856, 0.7160],\n",
      "        [0.5230, 0.5113, 0.4859, 0.7203],\n",
      "        ...,\n",
      "        [0.5238, 0.5170, 0.4842, 0.7209],\n",
      "        [0.5231, 0.5179, 0.4854, 0.7213],\n",
      "        [0.5315, 0.5068, 0.4863, 0.7093]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5197, 0.5084, 0.4970, 0.6730],\n",
      "        [0.5256, 0.5091, 0.4857, 0.7298],\n",
      "        [0.5241, 0.5115, 0.4861, 0.7340],\n",
      "        ...,\n",
      "        [0.5248, 0.5172, 0.4844, 0.7342],\n",
      "        [0.5247, 0.5177, 0.4850, 0.7350],\n",
      "        [0.5325, 0.5065, 0.4864, 0.7254]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5209, 0.5090, 0.4967, 0.6861],\n",
      "        [0.5267, 0.5094, 0.4858, 0.7433],\n",
      "        [0.5252, 0.5117, 0.4863, 0.7474],\n",
      "        ...,\n",
      "        [0.5257, 0.5174, 0.4849, 0.7470],\n",
      "        [0.5258, 0.5178, 0.4854, 0.7478],\n",
      "        [0.5335, 0.5063, 0.4858, 0.7410]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5220, 0.5096, 0.4965, 0.6991],\n",
      "        [0.5278, 0.5096, 0.4860, 0.7565],\n",
      "        [0.5264, 0.5120, 0.4865, 0.7606],\n",
      "        ...,\n",
      "        [0.5267, 0.5176, 0.4854, 0.7598],\n",
      "        [0.5269, 0.5179, 0.4859, 0.7605],\n",
      "        [0.5347, 0.5063, 0.4846, 0.7551]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5231, 0.5100, 0.4962, 0.7122],\n",
      "        [0.5289, 0.5099, 0.4862, 0.7694],\n",
      "        [0.5276, 0.5122, 0.4868, 0.7734],\n",
      "        ...,\n",
      "        [0.5278, 0.5171, 0.4856, 0.7746],\n",
      "        [0.5281, 0.5175, 0.4861, 0.7750],\n",
      "        [0.5362, 0.5062, 0.4838, 0.7695]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5242, 0.5104, 0.4959, 0.7251],\n",
      "        [0.5301, 0.5102, 0.4864, 0.7820],\n",
      "        [0.5288, 0.5124, 0.4870, 0.7860],\n",
      "        ...,\n",
      "        [0.5290, 0.5168, 0.4857, 0.7874],\n",
      "        [0.5293, 0.5171, 0.4861, 0.7880],\n",
      "        [0.5379, 0.5068, 0.4828, 0.7839]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5252, 0.5107, 0.4956, 0.7378],\n",
      "        [0.5313, 0.5105, 0.4866, 0.7941],\n",
      "        [0.5301, 0.5126, 0.4872, 0.7981],\n",
      "        ...,\n",
      "        [0.5303, 0.5165, 0.4857, 0.7988],\n",
      "        [0.5305, 0.5169, 0.4862, 0.7992],\n",
      "        [0.5407, 0.5076, 0.4826, 0.7982]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5263, 0.5109, 0.4953, 0.7502],\n",
      "        [0.5325, 0.5108, 0.4869, 0.8059],\n",
      "        [0.5314, 0.5128, 0.4875, 0.8099],\n",
      "        ...,\n",
      "        [0.5315, 0.5163, 0.4858, 0.8097],\n",
      "        [0.5315, 0.5169, 0.4865, 0.8100],\n",
      "        [0.5442, 0.5080, 0.4833, 0.8124]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5274, 0.5112, 0.4951, 0.7624],\n",
      "        [0.5337, 0.5111, 0.4871, 0.8172],\n",
      "        [0.5328, 0.5130, 0.4877, 0.8212],\n",
      "        ...,\n",
      "        [0.5325, 0.5162, 0.4862, 0.8203],\n",
      "        [0.5325, 0.5168, 0.4870, 0.8204],\n",
      "        [0.5460, 0.5082, 0.4838, 0.8249]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5285, 0.5114, 0.4949, 0.7743],\n",
      "        [0.5350, 0.5115, 0.4874, 0.8281],\n",
      "        [0.5341, 0.5132, 0.4879, 0.8321],\n",
      "        ...,\n",
      "        [0.5335, 0.5160, 0.4868, 0.8305],\n",
      "        [0.5334, 0.5167, 0.4875, 0.8306],\n",
      "        [0.5477, 0.5083, 0.4853, 0.8371]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5297, 0.5115, 0.4947, 0.7858],\n",
      "        [0.5363, 0.5118, 0.4877, 0.8385],\n",
      "        [0.5355, 0.5134, 0.4882, 0.8425],\n",
      "        ...,\n",
      "        [0.5346, 0.5159, 0.4873, 0.8405],\n",
      "        [0.5343, 0.5166, 0.4881, 0.8407],\n",
      "        [0.5493, 0.5088, 0.4863, 0.8482]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5308, 0.5117, 0.4945, 0.7970],\n",
      "        [0.5376, 0.5121, 0.4879, 0.8485],\n",
      "        [0.5369, 0.5136, 0.4884, 0.8523],\n",
      "        ...,\n",
      "        [0.5356, 0.5158, 0.4880, 0.8503],\n",
      "        [0.5354, 0.5164, 0.4887, 0.8505],\n",
      "        [0.5506, 0.5097, 0.4870, 0.8584]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5319, 0.5119, 0.4944, 0.8078],\n",
      "        [0.5390, 0.5124, 0.4882, 0.8579],\n",
      "        [0.5383, 0.5139, 0.4887, 0.8617],\n",
      "        ...,\n",
      "        [0.5369, 0.5159, 0.4889, 0.8598],\n",
      "        [0.5365, 0.5165, 0.4895, 0.8602],\n",
      "        [0.5518, 0.5104, 0.4875, 0.8678]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5330, 0.5121, 0.4943, 0.8181],\n",
      "        [0.5404, 0.5128, 0.4885, 0.8668],\n",
      "        [0.5397, 0.5141, 0.4889, 0.8705],\n",
      "        ...,\n",
      "        [0.5381, 0.5162, 0.4899, 0.8689],\n",
      "        [0.5378, 0.5166, 0.4904, 0.8694],\n",
      "        [0.5528, 0.5110, 0.4878, 0.8763]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5341, 0.5124, 0.4942, 0.8279],\n",
      "        [0.5418, 0.5131, 0.4888, 0.8753],\n",
      "        [0.5412, 0.5144, 0.4892, 0.8788],\n",
      "        ...,\n",
      "        [0.5394, 0.5165, 0.4908, 0.8773],\n",
      "        [0.5390, 0.5167, 0.4912, 0.8779],\n",
      "        [0.5539, 0.5115, 0.4879, 0.8841]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5352, 0.5127, 0.4941, 0.8373],\n",
      "        [0.5432, 0.5134, 0.4891, 0.8832],\n",
      "        [0.5426, 0.5146, 0.4895, 0.8866],\n",
      "        ...,\n",
      "        [0.5407, 0.5166, 0.4916, 0.8851],\n",
      "        [0.5402, 0.5167, 0.4918, 0.8858],\n",
      "        [0.5549, 0.5119, 0.4880, 0.8912]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5364, 0.5130, 0.4941, 0.8461],\n",
      "        [0.5446, 0.5138, 0.4894, 0.8906],\n",
      "        [0.5441, 0.5149, 0.4897, 0.8939],\n",
      "        ...,\n",
      "        [0.5419, 0.5166, 0.4922, 0.8924],\n",
      "        [0.5414, 0.5166, 0.4924, 0.8929],\n",
      "        [0.5559, 0.5122, 0.4881, 0.8977]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5375, 0.5134, 0.4940, 0.8545],\n",
      "        [0.5461, 0.5141, 0.4896, 0.8976],\n",
      "        [0.5455, 0.5151, 0.4900, 0.9007],\n",
      "        ...,\n",
      "        [0.5432, 0.5165, 0.4927, 0.8992],\n",
      "        [0.5427, 0.5165, 0.4930, 0.8996],\n",
      "        [0.5570, 0.5124, 0.4882, 0.9038]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5386, 0.5138, 0.4940, 0.8624],\n",
      "        [0.5476, 0.5144, 0.4899, 0.9041],\n",
      "        [0.5470, 0.5154, 0.4903, 0.9071],\n",
      "        ...,\n",
      "        [0.5444, 0.5165, 0.4932, 0.9055],\n",
      "        [0.5439, 0.5165, 0.4935, 0.9057],\n",
      "        [0.5582, 0.5127, 0.4884, 0.9096]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5397, 0.5142, 0.4941, 0.8698],\n",
      "        [0.5491, 0.5147, 0.4902, 0.9102],\n",
      "        [0.5485, 0.5156, 0.4906, 0.9130],\n",
      "        ...,\n",
      "        [0.5457, 0.5165, 0.4937, 0.9113],\n",
      "        [0.5451, 0.5165, 0.4941, 0.9113],\n",
      "        [0.5594, 0.5130, 0.4888, 0.9150]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5408, 0.5147, 0.4941, 0.8768],\n",
      "        [0.5506, 0.5151, 0.4905, 0.9159],\n",
      "        [0.5500, 0.5159, 0.4910, 0.9185],\n",
      "        ...,\n",
      "        [0.5469, 0.5166, 0.4941, 0.9165],\n",
      "        [0.5463, 0.5166, 0.4946, 0.9164],\n",
      "        [0.5607, 0.5134, 0.4893, 0.9200]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5419, 0.5151, 0.4942, 0.8833],\n",
      "        [0.5521, 0.5154, 0.4908, 0.9211],\n",
      "        [0.5514, 0.5162, 0.4913, 0.9236],\n",
      "        ...,\n",
      "        [0.5482, 0.5167, 0.4944, 0.9214],\n",
      "        [0.5474, 0.5167, 0.4951, 0.9212],\n",
      "        [0.5621, 0.5137, 0.4897, 0.9247]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5431, 0.5156, 0.4944, 0.8895],\n",
      "        [0.5536, 0.5157, 0.4911, 0.9260],\n",
      "        [0.5529, 0.5165, 0.4916, 0.9283],\n",
      "        ...,\n",
      "        [0.5495, 0.5169, 0.4947, 0.9259],\n",
      "        [0.5487, 0.5169, 0.4954, 0.9257],\n",
      "        [0.5634, 0.5141, 0.4902, 0.9290]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5442, 0.5161, 0.4945, 0.8953],\n",
      "        [0.5551, 0.5160, 0.4914, 0.9306],\n",
      "        [0.5544, 0.5168, 0.4920, 0.9327],\n",
      "        ...,\n",
      "        [0.5508, 0.5171, 0.4950, 0.9301],\n",
      "        [0.5500, 0.5170, 0.4956, 0.9299],\n",
      "        [0.5646, 0.5144, 0.4905, 0.9329]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5454, 0.5166, 0.4947, 0.9007],\n",
      "        [0.5567, 0.5163, 0.4917, 0.9348],\n",
      "        [0.5559, 0.5171, 0.4923, 0.9367],\n",
      "        ...,\n",
      "        [0.5521, 0.5174, 0.4953, 0.9340],\n",
      "        [0.5514, 0.5173, 0.4959, 0.9338],\n",
      "        [0.5658, 0.5148, 0.4908, 0.9365]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5465, 0.5172, 0.4949, 0.9058],\n",
      "        [0.5582, 0.5167, 0.4921, 0.9387],\n",
      "        [0.5574, 0.5173, 0.4927, 0.9405],\n",
      "        ...,\n",
      "        [0.5534, 0.5177, 0.4956, 0.9377],\n",
      "        [0.5529, 0.5176, 0.4961, 0.9375],\n",
      "        [0.5670, 0.5153, 0.4910, 0.9398]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5477, 0.5177, 0.4952, 0.9105],\n",
      "        [0.5598, 0.5170, 0.4924, 0.9423],\n",
      "        [0.5589, 0.5176, 0.4931, 0.9440],\n",
      "        ...,\n",
      "        [0.5548, 0.5180, 0.4959, 0.9410],\n",
      "        [0.5544, 0.5179, 0.4963, 0.9410],\n",
      "        [0.5681, 0.5157, 0.4912, 0.9430]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5489, 0.5182, 0.4955, 0.9150],\n",
      "        [0.5613, 0.5173, 0.4928, 0.9456],\n",
      "        [0.5604, 0.5179, 0.4935, 0.9472],\n",
      "        ...,\n",
      "        [0.5562, 0.5184, 0.4961, 0.9442],\n",
      "        [0.5559, 0.5182, 0.4965, 0.9442],\n",
      "        [0.5692, 0.5163, 0.4914, 0.9459]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5501, 0.5187, 0.4957, 0.9192],\n",
      "        [0.5628, 0.5176, 0.4932, 0.9487],\n",
      "        [0.5619, 0.5182, 0.4939, 0.9502],\n",
      "        ...,\n",
      "        [0.5577, 0.5187, 0.4963, 0.9472],\n",
      "        [0.5574, 0.5185, 0.4967, 0.9472],\n",
      "        [0.5703, 0.5168, 0.4915, 0.9487]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5513, 0.5192, 0.4961, 0.9232],\n",
      "        [0.5644, 0.5180, 0.4935, 0.9516],\n",
      "        [0.5635, 0.5185, 0.4943, 0.9530],\n",
      "        ...,\n",
      "        [0.5593, 0.5191, 0.4965, 0.9500],\n",
      "        [0.5590, 0.5189, 0.4968, 0.9499],\n",
      "        [0.5715, 0.5174, 0.4917, 0.9514]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5525, 0.5197, 0.4964, 0.9269],\n",
      "        [0.5659, 0.5183, 0.4939, 0.9543],\n",
      "        [0.5650, 0.5188, 0.4947, 0.9556],\n",
      "        ...,\n",
      "        [0.5611, 0.5194, 0.4966, 0.9526],\n",
      "        [0.5607, 0.5191, 0.4969, 0.9525],\n",
      "        [0.5728, 0.5179, 0.4920, 0.9540]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5538, 0.5202, 0.4967, 0.9304],\n",
      "        [0.5675, 0.5186, 0.4943, 0.9567],\n",
      "        [0.5664, 0.5192, 0.4951, 0.9580],\n",
      "        ...,\n",
      "        [0.5634, 0.5198, 0.4964, 0.9551],\n",
      "        [0.5626, 0.5194, 0.4969, 0.9550],\n",
      "        [0.5744, 0.5185, 0.4926, 0.9564]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5550, 0.5207, 0.4970, 0.9337],\n",
      "        [0.5690, 0.5189, 0.4948, 0.9590],\n",
      "        [0.5679, 0.5195, 0.4956, 0.9602],\n",
      "        ...,\n",
      "        [0.5659, 0.5202, 0.4962, 0.9575],\n",
      "        [0.5649, 0.5198, 0.4967, 0.9574],\n",
      "        [0.5764, 0.5191, 0.4933, 0.9588]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5563, 0.5211, 0.4974, 0.9367],\n",
      "        [0.5705, 0.5193, 0.4952, 0.9612],\n",
      "        [0.5694, 0.5198, 0.4961, 0.9623],\n",
      "        ...,\n",
      "        [0.5683, 0.5206, 0.4962, 0.9597],\n",
      "        [0.5673, 0.5202, 0.4965, 0.9596],\n",
      "        [0.5784, 0.5197, 0.4940, 0.9610]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5575, 0.5216, 0.4978, 0.9396],\n",
      "        [0.5720, 0.5196, 0.4956, 0.9632],\n",
      "        [0.5709, 0.5201, 0.4965, 0.9642],\n",
      "        ...,\n",
      "        [0.5708, 0.5210, 0.4963, 0.9618],\n",
      "        [0.5695, 0.5205, 0.4965, 0.9616],\n",
      "        [0.5799, 0.5202, 0.4946, 0.9630]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5588, 0.5221, 0.4981, 0.9424],\n",
      "        [0.5735, 0.5199, 0.4961, 0.9650],\n",
      "        [0.5724, 0.5204, 0.4970, 0.9660],\n",
      "        ...,\n",
      "        [0.5732, 0.5214, 0.4965, 0.9637],\n",
      "        [0.5718, 0.5208, 0.4966, 0.9635],\n",
      "        [0.5813, 0.5207, 0.4952, 0.9648]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5601, 0.5225, 0.4985, 0.9449],\n",
      "        [0.5750, 0.5203, 0.4965, 0.9667],\n",
      "        [0.5738, 0.5207, 0.4975, 0.9676],\n",
      "        ...,\n",
      "        [0.5751, 0.5216, 0.4968, 0.9654],\n",
      "        [0.5742, 0.5212, 0.4968, 0.9653],\n",
      "        [0.5825, 0.5211, 0.4957, 0.9664]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5614, 0.5229, 0.4989, 0.9473],\n",
      "        [0.5765, 0.5206, 0.4970, 0.9683],\n",
      "        [0.5753, 0.5210, 0.4980, 0.9692],\n",
      "        ...,\n",
      "        [0.5767, 0.5217, 0.4970, 0.9670],\n",
      "        [0.5763, 0.5215, 0.4971, 0.9669],\n",
      "        [0.5837, 0.5215, 0.4962, 0.9680]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5627, 0.5234, 0.4992, 0.9496],\n",
      "        [0.5779, 0.5209, 0.4975, 0.9698],\n",
      "        [0.5767, 0.5214, 0.4985, 0.9706],\n",
      "        ...,\n",
      "        [0.5781, 0.5219, 0.4973, 0.9684],\n",
      "        [0.5780, 0.5218, 0.4974, 0.9684],\n",
      "        [0.5850, 0.5219, 0.4967, 0.9695]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5640, 0.5238, 0.4996, 0.9517],\n",
      "        [0.5794, 0.5213, 0.4980, 0.9712],\n",
      "        [0.5781, 0.5217, 0.4990, 0.9720],\n",
      "        ...,\n",
      "        [0.5795, 0.5221, 0.4976, 0.9697],\n",
      "        [0.5795, 0.5220, 0.4978, 0.9697],\n",
      "        [0.5862, 0.5223, 0.4972, 0.9709]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5653, 0.5242, 0.5000, 0.9538],\n",
      "        [0.5808, 0.5216, 0.4985, 0.9725],\n",
      "        [0.5796, 0.5220, 0.4995, 0.9733],\n",
      "        ...,\n",
      "        [0.5809, 0.5222, 0.4979, 0.9710],\n",
      "        [0.5809, 0.5222, 0.4981, 0.9710],\n",
      "        [0.5875, 0.5227, 0.4977, 0.9722]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5666, 0.5246, 0.5004, 0.9556],\n",
      "        [0.5823, 0.5219, 0.4990, 0.9737],\n",
      "        [0.5810, 0.5223, 0.5001, 0.9744],\n",
      "        ...,\n",
      "        [0.5822, 0.5224, 0.4983, 0.9721],\n",
      "        [0.5823, 0.5224, 0.4985, 0.9721],\n",
      "        [0.5888, 0.5231, 0.4982, 0.9735]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5679, 0.5250, 0.5008, 0.9574],\n",
      "        [0.5837, 0.5223, 0.4996, 0.9749],\n",
      "        [0.5824, 0.5226, 0.5006, 0.9755],\n",
      "        ...,\n",
      "        [0.5836, 0.5226, 0.4987, 0.9732],\n",
      "        [0.5836, 0.5226, 0.4989, 0.9732],\n",
      "        [0.5900, 0.5235, 0.4986, 0.9747]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5692, 0.5254, 0.5012, 0.9591],\n",
      "        [0.5851, 0.5226, 0.5001, 0.9759],\n",
      "        [0.5838, 0.5230, 0.5012, 0.9766],\n",
      "        ...,\n",
      "        [0.5849, 0.5228, 0.4991, 0.9743],\n",
      "        [0.5850, 0.5228, 0.4993, 0.9743],\n",
      "        [0.5914, 0.5238, 0.4991, 0.9758]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5705, 0.5258, 0.5016, 0.9607],\n",
      "        [0.5865, 0.5230, 0.5006, 0.9769],\n",
      "        [0.5852, 0.5233, 0.5017, 0.9776],\n",
      "        ...,\n",
      "        [0.5862, 0.5230, 0.4995, 0.9752],\n",
      "        [0.5863, 0.5230, 0.4997, 0.9752],\n",
      "        [0.5927, 0.5242, 0.4996, 0.9769]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5719, 0.5262, 0.5020, 0.9622],\n",
      "        [0.5879, 0.5233, 0.5012, 0.9779],\n",
      "        [0.5866, 0.5236, 0.5023, 0.9785],\n",
      "        ...,\n",
      "        [0.5876, 0.5233, 0.4999, 0.9762],\n",
      "        [0.5877, 0.5232, 0.5001, 0.9762],\n",
      "        [0.5940, 0.5246, 0.5001, 0.9779]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5732, 0.5266, 0.5024, 0.9636],\n",
      "        [0.5894, 0.5237, 0.5017, 0.9788],\n",
      "        [0.5880, 0.5240, 0.5029, 0.9793],\n",
      "        ...,\n",
      "        [0.5889, 0.5235, 0.5003, 0.9771],\n",
      "        [0.5890, 0.5234, 0.5005, 0.9770],\n",
      "        [0.5954, 0.5250, 0.5005, 0.9789]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5745, 0.5270, 0.5028, 0.9650],\n",
      "        [0.5908, 0.5240, 0.5023, 0.9796],\n",
      "        [0.5894, 0.5243, 0.5034, 0.9802],\n",
      "        ...,\n",
      "        [0.5902, 0.5237, 0.5007, 0.9779],\n",
      "        [0.5903, 0.5236, 0.5010, 0.9779],\n",
      "        [0.5968, 0.5254, 0.5010, 0.9798]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5759, 0.5274, 0.5032, 0.9662],\n",
      "        [0.5922, 0.5244, 0.5029, 0.9804],\n",
      "        [0.5908, 0.5247, 0.5040, 0.9809],\n",
      "        ...,\n",
      "        [0.5915, 0.5239, 0.5012, 0.9787],\n",
      "        [0.5917, 0.5239, 0.5015, 0.9787],\n",
      "        [0.5983, 0.5258, 0.5014, 0.9806]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5772, 0.5278, 0.5036, 0.9674],\n",
      "        [0.5936, 0.5247, 0.5035, 0.9811],\n",
      "        [0.5922, 0.5250, 0.5046, 0.9817],\n",
      "        ...,\n",
      "        [0.5928, 0.5241, 0.5017, 0.9794],\n",
      "        [0.5930, 0.5241, 0.5019, 0.9794],\n",
      "        [0.5998, 0.5263, 0.5017, 0.9814]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5785, 0.5281, 0.5040, 0.9686],\n",
      "        [0.5950, 0.5251, 0.5041, 0.9818],\n",
      "        [0.5936, 0.5253, 0.5052, 0.9823],\n",
      "        ...,\n",
      "        [0.5942, 0.5243, 0.5022, 0.9802],\n",
      "        [0.5943, 0.5243, 0.5024, 0.9802],\n",
      "        [0.6015, 0.5267, 0.5019, 0.9822]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5799, 0.5285, 0.5044, 0.9697],\n",
      "        [0.5964, 0.5254, 0.5047, 0.9825],\n",
      "        [0.5950, 0.5257, 0.5058, 0.9830],\n",
      "        ...,\n",
      "        [0.5955, 0.5246, 0.5027, 0.9809],\n",
      "        [0.5956, 0.5245, 0.5029, 0.9808],\n",
      "        [0.6033, 0.5272, 0.5021, 0.9829]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5812, 0.5289, 0.5048, 0.9707],\n",
      "        [0.5978, 0.5258, 0.5053, 0.9831],\n",
      "        [0.5964, 0.5260, 0.5064, 0.9836],\n",
      "        ...,\n",
      "        [0.5967, 0.5248, 0.5032, 0.9815],\n",
      "        [0.5969, 0.5247, 0.5035, 0.9815],\n",
      "        [0.6050, 0.5277, 0.5023, 0.9836]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5826, 0.5293, 0.5052, 0.9717],\n",
      "        [0.5991, 0.5262, 0.5059, 0.9837],\n",
      "        [0.5978, 0.5264, 0.5071, 0.9842],\n",
      "        ...,\n",
      "        [0.5980, 0.5250, 0.5038, 0.9822],\n",
      "        [0.5982, 0.5250, 0.5040, 0.9821],\n",
      "        [0.6067, 0.5281, 0.5026, 0.9842]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5839, 0.5297, 0.5057, 0.9726],\n",
      "        [0.6005, 0.5265, 0.5065, 0.9843],\n",
      "        [0.5992, 0.5267, 0.5077, 0.9847],\n",
      "        ...,\n",
      "        [0.5993, 0.5253, 0.5043, 0.9827],\n",
      "        [0.5995, 0.5252, 0.5046, 0.9827],\n",
      "        [0.6083, 0.5285, 0.5029, 0.9848]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5852, 0.5301, 0.5061, 0.9735],\n",
      "        [0.6019, 0.5269, 0.5071, 0.9848],\n",
      "        [0.6006, 0.5271, 0.5083, 0.9852],\n",
      "        ...,\n",
      "        [0.6005, 0.5256, 0.5049, 0.9833],\n",
      "        [0.6007, 0.5255, 0.5052, 0.9833],\n",
      "        [0.6098, 0.5289, 0.5034, 0.9854]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5866, 0.5305, 0.5065, 0.9743],\n",
      "        [0.6033, 0.5272, 0.5077, 0.9853],\n",
      "        [0.6019, 0.5275, 0.5090, 0.9857],\n",
      "        ...,\n",
      "        [0.6018, 0.5258, 0.5056, 0.9839],\n",
      "        [0.6019, 0.5258, 0.5058, 0.9838],\n",
      "        [0.6112, 0.5293, 0.5039, 0.9859]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.5879, 0.5309, 0.5069, 0.9751],\n",
      "        [0.6047, 0.5276, 0.5084, 0.9858],\n",
      "        [0.6033, 0.5278, 0.5096, 0.9862],\n",
      "        ...,\n",
      "        [0.6030, 0.5261, 0.5062, 0.9844],\n",
      "        [0.6032, 0.5261, 0.5064, 0.9843],\n",
      "        [0.6127, 0.5296, 0.5044, 0.9864]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-0c1a559ef435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m521\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_loss = 0\n",
    "for epoch in range(300):        \n",
    "        # Clear for the gradients.\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # here prepare the inputs and targets\n",
    "        # target = array of labels [0, 1, ] where the label i stands for the class of the word i\n",
    "        training_input = vectors\n",
    "        target = labels\n",
    "        \n",
    "        # run a forward pass\n",
    "        label_scores = model(training_input)\n",
    "        print(label_scores)\n",
    "        # Calculate loss, backpropagate, and update weights/parameters by calling opt.step()\n",
    "        loss = loss_function(label_scores, target)\n",
    "        batch_loss += loss.item()*521\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Epoch: {0}/300. Loss: {2:.2f} Progress: {1}%\".format(epoch, int((epoch * 100)/300), loss.item()) , end=\"\\r\")\n",
    "        \n",
    "\n",
    "print(\"Bi-LSTM model training is done!\", end='\\r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
