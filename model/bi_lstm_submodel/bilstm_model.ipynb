{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "\n",
    "torch.manual_seed(10)\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device = 'cpu'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# A common headache in this competition is the lack of determinism in the results due to cudnn, the following solves the issue\n",
    "def seed_everything(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Here i have to get the ELMO vector in a form, in a format of numpy array.\n",
    "with open('document_vector.pickle', 'rb') as file:\n",
    "    vectors = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "vectors = np.delete(vectors, 1, 1)\n",
    "vectors = np.delete(vectors, 0, 1)\n",
    "\n",
    "vectors = torch.from_numpy(np.array(vectors, dtype=np.float64)).view(521, 1, -1).float()\n",
    "vectors.size()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "vectors = np.array([])\n",
    "labels = np.array([])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reading the features NOTE: Do not run this it is already saved under vectors.pickle\n",
    "i = 0\n",
    "vectors = np.array([])\n",
    "labels = np.array([])\n",
    "for file in os.scandir('../../feature_extraction/features/'):\n",
    "    if file.name.endswith('csv'):\n",
    "        try:\n",
    "            vector = pd.read_csv(file)\n",
    "            if (vector.shape[1] == 1044 or vector.shape[1] == 1047):\n",
    "                # Some files have issues\n",
    "                continue\n",
    "            elif (vector.shape[1] == 1046):\n",
    "                # Some files have an unnecessary column\n",
    "                vector.drop([vector.columns[0]], axis=1, inplace=True)\n",
    "            if i == 0:\n",
    "                vectors = vector.to_numpy()\n",
    "            else: \n",
    "                vectors = np.concatenate((vectors, vector.to_numpy()))\n",
    "            i+=1\n",
    "            print(i, end=\"\\r\")\n",
    "        except:\n",
    "            continue"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "179\r"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3877\r"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "with open(\"./vectors.pickle\", \"wb\") as f:\n",
    "    pickle.dump(vectors, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "with open(\"./model_inputs/batch1.pickle\", 'rb') as f:\n",
    "    vectors = pickle.load(f)\n",
    "\n",
    "t = np.array(vectors)\n",
    "print(t.shape)\n",
    "\n",
    "rm_indexes = np.isnan(t[:, -1].astype(np.float))\n",
    "\n",
    "vectors = np.delete(t, rm_indexes, 0)\n",
    "\n",
    "print(vectors[1])\n",
    "print(vectors.shape)\n",
    "\n",
    "\n",
    "labels_list = vectors[:, [2, -1]]\n",
    "vectors = vectors[:, 3:-1]\n",
    "\n",
    "labels = labels_list[:, -1].astype(np.float)\n",
    "\n",
    "print(labels_list.shape)\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(30361, 1045)\n",
      "[1 1 'Chrysinas,' ... 0.0602333582937717 0.1984460353851318 1.0]\n",
      "(23976, 1045)\n",
      "(23976, 2)\n",
      "(23976,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1.0: 993,\n",
       " 2.0: 1210,\n",
       " 3.0: 255,\n",
       " 4.0: 32,\n",
       " 5.0: 297,\n",
       " 6.0: 77,\n",
       " 7.0: 10695,\n",
       " 8.0: 9,\n",
       " 9.0: 11,\n",
       " 10.0: 10397}"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "print(vectors.shape)\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(23976, 1041)\n",
      "(23976,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(vectors, labels, test_size=0.2, random_state=42,stratify=labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "x_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19180, 1041)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "x_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4796, 1041)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "y_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19180,)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "labels = torch.from_numpy(np.array(y_train, dtype=np.int64)).to(device)\n",
    "labels = labels -1\n",
    "print(labels.size())\n",
    "v = torch.from_numpy(np.array(x_train, dtype=np.float64)).view(-1, 1, 1041).float().to(device)\n",
    "print(v.size())\n",
    "\n",
    "v2 = torch.from_numpy(np.array(x_test, dtype=np.float64)).view(-1, 1, 1041).float().to(device)\n",
    "l2 = torch.from_numpy(np.array(y_test, dtype=np.int64)).to(device)\n",
    "l2 = l2 -1\n",
    "print(v2.size())\n",
    "print(l2.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([19180])\n",
      "torch.Size([19180, 1, 1041])\n",
      "torch.Size([4796, 1, 1041])\n",
      "torch.Size([4796])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "# Normalize the vectors\n",
    "train_mean = v.mean(dim=0, keepdim=True)\n",
    "train_std = v.std(dim=0, keepdim=True)\n",
    "normalized_v = (v - train_mean)/train_std\n",
    "\n",
    "test_mean = v2.mean(dim=0, keepdim=True)\n",
    "test_std = v2.std(dim=0, keepdim=True)\n",
    "normalized_v2 = (v2 - test_mean)/test_std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "print(normalized_v.size())\n",
    "print(normalized_v2.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([19180, 1, 1041])\n",
      "torch.Size([4796, 1, 1041])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "v.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([19180, 1, 1041])"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "normalized_v[torch.isnan(normalized_v)] = 0\n",
    "print(normalized_v.size())\n",
    "normalized_v2[torch.isnan(normalized_v2)] = 0\n",
    "print(normalized_v2.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([19180, 1, 1041])\n",
      "torch.Size([4796, 1, 1041])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "print(train_mean)\n",
    "print(train_std)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[ 0.0535,  0.2796,  0.0000,  ..., -0.0324,  0.1566, -0.1341]]])\n",
      "tensor([[[0.1270, 0.4488, 0.0000,  ..., 0.2853, 0.3057, 0.3370]]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset = dataset\n",
    "    def __getitem__(self,index):\n",
    "        data,target = self.dataset[index]\n",
    "        return data,target,index\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "train = MyDataset(torch.utils.data.TensorDataset(normalized_v, labels))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 128, shuffle=True)\n",
    "print(train_loader)\n",
    "\n",
    "validation = MyDataset(torch.utils.data.TensorDataset(normalized_v2, l2))\n",
    "validation_loader = torch.utils.data.DataLoader(validation, batch_size = 128, shuffle=True)\n",
    "print(train_loader)\n",
    "for x, y, i in validation_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(i)\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff3e3ebda30>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff3e3ebda30>\n",
      "tensor([[[-0.4326, -0.6365,  0.0000,  ...,  1.5858, -2.4075,  0.6017]],\n",
      "\n",
      "        [[-0.4326, -0.6365,  0.0000,  ...,  1.4890, -1.6941,  0.3707]],\n",
      "\n",
      "        [[-0.4326, -0.6365,  0.0000,  ..., -0.0131, -0.6066,  1.7695]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4697,  1.5708,  0.0000,  ...,  0.0290,  0.2364,  0.7139]],\n",
      "\n",
      "        [[-0.4326, -0.6365,  0.0000,  ..., -0.2750, -0.6404,  2.0389]],\n",
      "\n",
      "        [[ 0.9209,  1.5708,  0.0000,  ...,  0.3798,  0.0090, -0.1510]]])\n",
      "tensor([6, 9, 9, 9, 6, 6, 9, 9, 9, 9, 9, 9, 6, 6, 6, 0, 6, 6, 9, 9, 1, 0, 6, 9,\n",
      "        6, 6, 6, 6, 9, 6, 9, 6, 6, 6, 6, 1, 9, 9, 9, 6, 0, 9, 9, 6, 6, 9, 6, 9,\n",
      "        9, 0, 6, 9, 6, 9, 9, 6, 9, 9, 6, 6, 1, 9, 9, 6, 1, 9, 6, 6, 2, 6, 6, 9,\n",
      "        6, 6, 0, 6, 9, 0, 9, 6, 9, 9, 9, 1, 9, 9, 9, 6, 6, 9, 6, 9, 6, 9, 9, 6,\n",
      "        9, 6, 5, 6, 9, 9, 6, 6, 6, 6, 9, 9, 9, 9, 1, 1, 9, 9, 9, 6, 9, 1, 9, 6,\n",
      "        6, 6, 6, 9, 6, 0, 6, 1])\n",
      "tensor([ 800,  893, 4777, 3938, 4725, 4427, 3449, 1856, 4178, 1724,   50,   57,\n",
      "        4606, 1128, 2136, 1101, 3279,  536, 3992, 4388, 1490, 1416,  623, 2876,\n",
      "        3464, 1234, 3220, 4395, 2252,  323, 4556, 4651, 2779, 2359,  463, 4333,\n",
      "        2704, 3287, 3506,   85, 2587, 3190, 3353, 3710,  199, 4017, 4710, 4220,\n",
      "        4788,   66,  253, 1439,   49, 2211, 3027, 1682, 3281, 1748,  328,  941,\n",
      "        2843, 4114, 1679, 3738, 2502, 2055, 2385, 2467, 3625, 4542, 3680,  131,\n",
      "        1223, 1524,  926, 1240,  305, 2464, 1595, 1976, 1489, 1380, 3164, 1452,\n",
      "        4335, 3407, 1274,  519, 1571, 1040,  864, 3746, 1453, 1197,  870, 3010,\n",
      "          72, 2541,  824, 2666, 3692,  309,   45, 2167, 2758, 4125, 4579, 4147,\n",
      "        1825, 3206, 3066,  414, 2409, 2584, 2089, 1053, 2302, 2460, 1906, 3697,\n",
      "          56,  747, 4298, 1413, 4574,  506, 1359, 2735])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "class BiLSTM(nn.Module): \n",
    "    # This NLP part Will consist of two bidirectional lstm layers and it's output is \n",
    "    # determined by the LSTM's last hidden states or output vectors.\n",
    "\n",
    "    # This will take as an input a sequence of words and output the last hidden layer\n",
    "    # the last hidden states of 2-layer bidirectional LSTM will be the input of the last multimodel network \n",
    "\n",
    "    def __init__(self, input_size, hidden_dim = 256, layer_dim =2, output_dim = 10):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        \n",
    "        #self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.device = 'cpu'\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        #Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim # maybe set this to 256\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building the LSTM \n",
    "        # batch_first = True causes the input/output to be of shape 3D (batch_dim, seq_dim, feature_dim) \n",
    "        # output will be the same dim as the hidden dim\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_dim, layer_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        # self.layer_dim * 2. because we have one going forwards and another going backwards\n",
    "        h0 = torch.randn(self.layer_dim * 2, x.size(0), self.hidden_dim, device=self.device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialize cell state\n",
    "        c0 =  torch.randn(self.layer_dim * 2, x.size(0), self.hidden_dim, device=self.device)\n",
    "        \n",
    "        # We suppose we are conducting a 28 time steps In case of using \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm1(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        #out = self.fc(out.view(out.size(0), -1))\n",
    "          \n",
    "        # Without the activation function, out will contain the last hidden layer.\n",
    "        # This could be obtianed from hn[-1] as well.\n",
    "        out = out[:, -1, :]\n",
    "        out = self.dropout(self.fc(out))\n",
    "        return out\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 256, 100, 256 if we have (input dim = 100 and hidden dim = 100)\n",
    "        # out[:, -1, :] => 256, 256 --> because we just want the last time step hidden states\n",
    "        #out = out[:, -1, :] # without an activation function\n",
    "\n",
    "        # now our: out.size() --> 256, 10 (if output dimension is equal to 10)\n",
    "        #return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "# Training the model\n",
    "batch_loss = 0\n",
    "batch_size = 128\n",
    "epochs = 300\n",
    "\n",
    "# 1041 embedding size\n",
    "model = BiLSTM(1041)\n",
    "model.to(device)\n",
    "#model = BiLSTM(17)\n",
    "\n",
    "\n",
    "# Class weights (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "weights = torch.tensor([0.69,2.95,0.08,0.02,0.77,0.017,18.59,0 ,0.007,76.83], dtype=torch.float32)\n",
    "weights = weights / weights.sum()\n",
    "weights = 1.0 / weights\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "\n",
    "#loss_function = nn.NLLLoss()\n",
    "#criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#loss_function = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0003)\n",
    "\n",
    "train = MyDataset(torch.utils.data.TensorDataset(normalized_v, labels))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "losses = list()\n",
    "validation_losses = list()\n",
    "print_every = 100\n",
    "min_loss = np.Inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for i, (x_batch, y_batch, index) in enumerate(train_loader):\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # feed forward\n",
    "        label_scores = model(x_batch)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(label_scores, y_batch)\n",
    "        \n",
    "        # backpropagate and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate loss\n",
    "        running_loss += loss.item()*x_batch.size(0)\n",
    "    \n",
    "    train_loss = running_loss/len(train_loader.sampler)\n",
    "    losses.append(train_loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        accuracy = 0\n",
    "        model.eval()\n",
    "        for x, y, i in validation_loader:\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            val_loss += loss.item()*x.size(0)\n",
    "            \n",
    "            scores, classes = F.softmax(out, dim=1).topk(1, dim=1)\n",
    "            equals = classes == y.view(*classes.shape)\n",
    "            \n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "            \n",
    "        val_loss = val_loss/len(validation_loader.sampler)\n",
    "        accuracy = accuracy/len(validation_loader)\n",
    "            \n",
    "    validation_losses.append(val_loss)\n",
    "    print(\"Epoch: {0} | Training loss: {1} | Validation loss: {2} | Accuracy: \\t{3:.2f}\".format(epoch, train_loss, val_loss, accuracy))\n",
    "    \n",
    "    if (val_loss < min_loss):\n",
    "        torch.save(model.state_dict(), \"model_fixed_v1.pt\")\n",
    "        print(\"Loss decreased: {0} ==> {1}\".format(min_loss, val_loss))\n",
    "        min_loss = val_loss\n",
    "        \n",
    "print(\"Bi-LSTM model training is done!                           \", end='\\r')\n",
    "print(\"final labels {0}\".format(label_scores))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 | Training loss: 1.3924040461978773 | Validation loss: 0.7267836484439777 | Accuracy: \t0.73\n",
      "Loss decreased: inf ==> 0.7267836484439777\n",
      "Epoch: 1 | Training loss: 0.852650199928423 | Validation loss: 0.551864980458219 | Accuracy: \t0.80\n",
      "Loss decreased: 0.7267836484439777 ==> 0.551864980458219\n",
      "Epoch: 2 | Training loss: 0.7084449698455142 | Validation loss: 0.4589355192003497 | Accuracy: \t0.83\n",
      "Loss decreased: 0.551864980458219 ==> 0.4589355192003497\n",
      "Epoch: 3 | Training loss: 0.6269594432290826 | Validation loss: 0.4121852202451259 | Accuracy: \t0.85\n",
      "Loss decreased: 0.4589355192003497 ==> 0.4121852202451259\n",
      "Epoch: 4 | Training loss: 0.5784308826339133 | Validation loss: 0.3862876021384795 | Accuracy: \t0.87\n",
      "Loss decreased: 0.4121852202451259 ==> 0.3862876021384795\n",
      "Epoch: 5 | Training loss: 0.5449871791664577 | Validation loss: 0.3746173700210549 | Accuracy: \t0.86\n",
      "Loss decreased: 0.3862876021384795 ==> 0.3746173700210549\n",
      "Epoch: 6 | Training loss: 0.5152480081422983 | Validation loss: 0.3644063741938088 | Accuracy: \t0.87\n",
      "Loss decreased: 0.3746173700210549 ==> 0.3644063741938088\n",
      "Epoch: 7 | Training loss: 0.49958812304781175 | Validation loss: 0.35435467242598034 | Accuracy: \t0.87\n",
      "Loss decreased: 0.3644063741938088 ==> 0.35435467242598034\n",
      "Epoch: 8 | Training loss: 0.47991913553944965 | Validation loss: 0.35098805794922683 | Accuracy: \t0.88\n",
      "Loss decreased: 0.35435467242598034 ==> 0.35098805794922683\n",
      "Epoch: 9 | Training loss: 0.4712261355519916 | Validation loss: 0.3525005568306679 | Accuracy: \t0.87\n",
      "Epoch: 10 | Training loss: 0.4603622793281165 | Validation loss: 0.3414606325471272 | Accuracy: \t0.88\n",
      "Loss decreased: 0.35098805794922683 ==> 0.3414606325471272\n",
      "Epoch: 11 | Training loss: 0.44561561176376624 | Validation loss: 0.3386165218317479 | Accuracy: \t0.88\n",
      "Loss decreased: 0.3414606325471272 ==> 0.3386165218317479\n",
      "Epoch: 12 | Training loss: 0.44229513736163983 | Validation loss: 0.33258346446461234 | Accuracy: \t0.88\n",
      "Loss decreased: 0.3386165218317479 ==> 0.33258346446461234\n",
      "Epoch: 13 | Training loss: 0.42764592311802446 | Validation loss: 0.3458082379153413 | Accuracy: \t0.88\n",
      "Epoch: 14 | Training loss: 0.4248547400001192 | Validation loss: 0.34303329625260937 | Accuracy: \t0.88\n",
      "Epoch: 15 | Training loss: 0.4245014423995868 | Validation loss: 0.33677022329363054 | Accuracy: \t0.88\n",
      "Epoch: 16 | Training loss: 0.41271979755977395 | Validation loss: 0.3415959744377868 | Accuracy: \t0.89\n",
      "Epoch: 17 | Training loss: 0.41639509577074935 | Validation loss: 0.34213043171430846 | Accuracy: \t0.88\n",
      "Epoch: 18 | Training loss: 0.40166305152542026 | Validation loss: 0.34612141496146887 | Accuracy: \t0.88\n",
      "Epoch: 19 | Training loss: 0.39589659621369977 | Validation loss: 0.3515327818151113 | Accuracy: \t0.88\n",
      "Epoch: 20 | Training loss: 0.39368520380309524 | Validation loss: 0.3491875775114907 | Accuracy: \t0.88\n",
      "Epoch: 21 | Training loss: 0.3984800129911325 | Validation loss: 0.3613025112585588 | Accuracy: \t0.88\n",
      "Epoch: 22 | Training loss: 0.3914273087249931 | Validation loss: 0.3551180961979141 | Accuracy: \t0.88\n",
      "Epoch: 23 | Training loss: 0.3899134862099748 | Validation loss: 0.356721426841117 | Accuracy: \t0.88\n",
      "Epoch: 24 | Training loss: 0.3816764408343776 | Validation loss: 0.35067538464685793 | Accuracy: \t0.89\n",
      "Epoch: 25 | Training loss: 0.38177205887278376 | Validation loss: 0.3564422420902586 | Accuracy: \t0.89\n",
      "Epoch: 26 | Training loss: 0.3798425329987026 | Validation loss: 0.35685938348165647 | Accuracy: \t0.89\n",
      "Epoch: 27 | Training loss: 0.3785996877115387 | Validation loss: 0.3546971436388001 | Accuracy: \t0.88\n",
      "Epoch: 28 | Training loss: 0.3775405577126584 | Validation loss: 0.36540768057530476 | Accuracy: \t0.89\n",
      "Epoch: 29 | Training loss: 0.36983575142834557 | Validation loss: 0.35612320077230375 | Accuracy: \t0.89\n",
      "Epoch: 30 | Training loss: 0.37104568981154745 | Validation loss: 0.3590674590726412 | Accuracy: \t0.88\n",
      "Epoch: 31 | Training loss: 0.36908937800788283 | Validation loss: 0.35126074353191034 | Accuracy: \t0.89\n",
      "Epoch: 32 | Training loss: 0.36227081427981883 | Validation loss: 0.3770962594150006 | Accuracy: \t0.89\n",
      "Epoch: 33 | Training loss: 0.36659191411777137 | Validation loss: 0.37398644362120353 | Accuracy: \t0.89\n",
      "Epoch: 34 | Training loss: 0.3690097018998656 | Validation loss: 0.3694188810319479 | Accuracy: \t0.89\n",
      "Epoch: 35 | Training loss: 0.3669362785483053 | Validation loss: 0.38929614854713995 | Accuracy: \t0.89\n",
      "Epoch: 36 | Training loss: 0.3703187108412773 | Validation loss: 0.38506812309602384 | Accuracy: \t0.88\n",
      "Epoch: 37 | Training loss: 0.36430971119649963 | Validation loss: 0.3704358735762605 | Accuracy: \t0.89\n",
      "Epoch: 38 | Training loss: 0.3611570939779033 | Validation loss: 0.37230397151896516 | Accuracy: \t0.89\n",
      "Epoch: 39 | Training loss: 0.36242296742323915 | Validation loss: 0.3701923821149417 | Accuracy: \t0.89\n",
      "Epoch: 40 | Training loss: 0.3579264285013748 | Validation loss: 0.3837622399251594 | Accuracy: \t0.89\n",
      "Epoch: 41 | Training loss: 0.3523448008131061 | Validation loss: 0.3766756835482934 | Accuracy: \t0.89\n",
      "Epoch: 42 | Training loss: 0.3554223373361375 | Validation loss: 0.37944272237583637 | Accuracy: \t0.89\n",
      "Epoch: 43 | Training loss: 0.3442313872114585 | Validation loss: 0.3954161365296664 | Accuracy: \t0.89\n",
      "Epoch: 44 | Training loss: 0.35605609604041943 | Validation loss: 0.39686546793473176 | Accuracy: \t0.89\n",
      "Epoch: 45 | Training loss: 0.3522954358609551 | Validation loss: 0.3939850639809759 | Accuracy: \t0.89\n",
      "Epoch: 46 | Training loss: 0.3569838478928189 | Validation loss: 0.39368059234483926 | Accuracy: \t0.89\n",
      "Epoch: 47 | Training loss: 0.34778990229053713 | Validation loss: 0.39024820434142393 | Accuracy: \t0.89\n",
      "Epoch: 48 | Training loss: 0.3498513282650579 | Validation loss: 0.407131398290868 | Accuracy: \t0.89\n",
      "Epoch: 49 | Training loss: 0.34873877020399313 | Validation loss: 0.39098817167230404 | Accuracy: \t0.89\n",
      "Epoch: 50 | Training loss: 0.34587279532077536 | Validation loss: 0.41069894141709434 | Accuracy: \t0.89\n",
      "Epoch: 51 | Training loss: 0.34147714094896886 | Validation loss: 0.4001822766659158 | Accuracy: \t0.89\n",
      "Epoch: 52 | Training loss: 0.3427678273728543 | Validation loss: 0.39664879366693345 | Accuracy: \t0.89\n",
      "Epoch: 53 | Training loss: 0.3467283589685796 | Validation loss: 0.4033995660719422 | Accuracy: \t0.89\n",
      "Epoch: 54 | Training loss: 0.3478820528924403 | Validation loss: 0.41460657078738605 | Accuracy: \t0.89\n",
      "Epoch: 55 | Training loss: 0.333896417706055 | Validation loss: 0.4128392889561307 | Accuracy: \t0.89\n",
      "Epoch: 56 | Training loss: 0.3415240914655055 | Validation loss: 0.4157584713984769 | Accuracy: \t0.89\n",
      "Epoch: 57 | Training loss: 0.34309978499402594 | Validation loss: 0.40300761432922116 | Accuracy: \t0.89\n",
      "Epoch: 58 | Training loss: 0.34332578832339944 | Validation loss: 0.40748547340702074 | Accuracy: \t0.89\n",
      "Epoch: 59 | Training loss: 0.33893064205788226 | Validation loss: 0.4156673888150009 | Accuracy: \t0.89\n",
      "Epoch: 60 | Training loss: 0.340877627493567 | Validation loss: 0.42669806934526505 | Accuracy: \t0.89\n",
      "Epoch: 61 | Training loss: 0.3341682746897649 | Validation loss: 0.41868055522988695 | Accuracy: \t0.89\n",
      "Epoch: 62 | Training loss: 0.33813741457599045 | Validation loss: 0.4104038276356195 | Accuracy: \t0.89\n",
      "Epoch: 63 | Training loss: 0.334370690546891 | Validation loss: 0.42857056378920544 | Accuracy: \t0.89\n",
      "Epoch: 64 | Training loss: 0.3345704349971787 | Validation loss: 0.4205166627905387 | Accuracy: \t0.89\n",
      "Epoch: 65 | Training loss: 0.33833967497624745 | Validation loss: 0.44594044967230606 | Accuracy: \t0.89\n",
      "Epoch: 66 | Training loss: 0.33688643138401203 | Validation loss: 0.40989705142227184 | Accuracy: \t0.89\n",
      "Epoch: 67 | Training loss: 0.32911125250603535 | Validation loss: 0.42584985579123985 | Accuracy: \t0.89\n",
      "Epoch: 68 | Training loss: 0.32739181481884466 | Validation loss: 0.4203269543301771 | Accuracy: \t0.89\n",
      "Epoch: 69 | Training loss: 0.33061591522288397 | Validation loss: 0.4097550172821694 | Accuracy: \t0.90\n",
      "Epoch: 70 | Training loss: 0.32971329361480023 | Validation loss: 0.4326253822189853 | Accuracy: \t0.89\n",
      "Epoch: 71 | Training loss: 0.3228309293733026 | Validation loss: 0.4264844972158691 | Accuracy: \t0.89\n",
      "Epoch: 72 | Training loss: 0.3286754970940857 | Validation loss: 0.43159233939657615 | Accuracy: \t0.89\n",
      "Epoch: 73 | Training loss: 0.3244232508885102 | Validation loss: 0.42822233312223434 | Accuracy: \t0.89\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 74 | Training loss: 0.3261596673782973 | Validation loss: 0.423675883204068 | Accuracy: \t0.89\n",
      "Epoch: 75 | Training loss: 0.32654647813474796 | Validation loss: 0.42604000107062867 | Accuracy: \t0.90\n",
      "Epoch: 76 | Training loss: 0.3237015668990341 | Validation loss: 0.42945584431104206 | Accuracy: \t0.89\n",
      "Epoch: 77 | Training loss: 0.32100739685412616 | Validation loss: 0.43971555023217224 | Accuracy: \t0.89\n",
      "Epoch: 78 | Training loss: 0.32425144742067213 | Validation loss: 0.447355089956169 | Accuracy: \t0.89\n",
      "Epoch: 79 | Training loss: 0.32963172064956214 | Validation loss: 0.45652972411572484 | Accuracy: \t0.89\n",
      "Epoch: 80 | Training loss: 0.3232514643258919 | Validation loss: 0.4282747718371184 | Accuracy: \t0.89\n",
      "Epoch: 81 | Training loss: 0.3272208320647012 | Validation loss: 0.4181611699000113 | Accuracy: \t0.90\n",
      "Epoch: 82 | Training loss: 0.3244254025291725 | Validation loss: 0.4530197417268761 | Accuracy: \t0.89\n",
      "Epoch: 83 | Training loss: 0.32865271703791693 | Validation loss: 0.4446643666862149 | Accuracy: \t0.89\n",
      "Epoch: 84 | Training loss: 0.32097755671790545 | Validation loss: 0.4266599501367407 | Accuracy: \t0.90\n",
      "Epoch: 85 | Training loss: 0.3155868577385347 | Validation loss: 0.46127048845684854 | Accuracy: \t0.89\n",
      "Epoch: 86 | Training loss: 0.31688701222972154 | Validation loss: 0.4347286770948278 | Accuracy: \t0.89\n",
      "Epoch: 87 | Training loss: 0.3202178821200748 | Validation loss: 0.4702453873771941 | Accuracy: \t0.89\n",
      "Epoch: 88 | Training loss: 0.3211939007012762 | Validation loss: 0.43940027411079485 | Accuracy: \t0.89\n",
      "Epoch: 89 | Training loss: 0.3178802519321939 | Validation loss: 0.45621506291891356 | Accuracy: \t0.89\n",
      "Epoch: 90 | Training loss: 0.31693621373524633 | Validation loss: 0.46530404456388563 | Accuracy: \t0.89\n",
      "Epoch: 91 | Training loss: 0.318897635316451 | Validation loss: 0.45676714358377496 | Accuracy: \t0.89\n",
      "Epoch: 92 | Training loss: 0.3102827116955806 | Validation loss: 0.4722267122841359 | Accuracy: \t0.89\n",
      "Epoch: 93 | Training loss: 0.3123566531445112 | Validation loss: 0.4400131201326499 | Accuracy: \t0.90\n",
      "Epoch: 94 | Training loss: 0.32094460258394386 | Validation loss: 0.42328048050652156 | Accuracy: \t0.90\n",
      "Epoch: 95 | Training loss: 0.3162161423901447 | Validation loss: 0.4573240921932822 | Accuracy: \t0.89\n",
      "Epoch: 96 | Training loss: 0.3171316183147888 | Validation loss: 0.4478907608757226 | Accuracy: \t0.89\n",
      "Epoch: 97 | Training loss: 0.317282697312899 | Validation loss: 0.44976181129896214 | Accuracy: \t0.90\n",
      "Epoch: 98 | Training loss: 0.313622029121029 | Validation loss: 0.45752475923354474 | Accuracy: \t0.89\n",
      "Epoch: 99 | Training loss: 0.3090605141969866 | Validation loss: 0.4599907184710992 | Accuracy: \t0.90\n",
      "Epoch: 100 | Training loss: 0.3117331085413912 | Validation loss: 0.4776843580432093 | Accuracy: \t0.90\n",
      "Epoch: 101 | Training loss: 0.30999622200775945 | Validation loss: 0.47321389313535556 | Accuracy: \t0.89\n",
      "Epoch: 102 | Training loss: 0.3118132702501275 | Validation loss: 0.4540456517027059 | Accuracy: \t0.90\n",
      "Epoch: 103 | Training loss: 0.31458847190839034 | Validation loss: 0.47407445338887905 | Accuracy: \t0.89\n",
      "Epoch: 104 | Training loss: 0.31298179733367854 | Validation loss: 0.4659325029076488 | Accuracy: \t0.89\n",
      "Epoch: 105 | Training loss: 0.30657108338458444 | Validation loss: 0.4895334176352563 | Accuracy: \t0.89\n",
      "Epoch: 106 | Training loss: 0.30671275905697637 | Validation loss: 0.4546196619180762 | Accuracy: \t0.90\n",
      "Epoch: 107 | Training loss: 0.3104852425231675 | Validation loss: 0.4708346338123953 | Accuracy: \t0.90\n",
      "Epoch: 108 | Training loss: 0.3151540569145314 | Validation loss: 0.47683688553300274 | Accuracy: \t0.90\n",
      "Epoch: 109 | Training loss: 0.30535153888313565 | Validation loss: 0.4698884401647522 | Accuracy: \t0.90\n",
      "Epoch: 110 | Training loss: 0.3082320969905296 | Validation loss: 0.4439209762143532 | Accuracy: \t0.90\n",
      "Epoch: 111 | Training loss: 0.3050523571227216 | Validation loss: 0.4560539175113904 | Accuracy: \t0.90\n",
      "Epoch: 112 | Training loss: 0.3104546137410483 | Validation loss: 0.4812601104788824 | Accuracy: \t0.90\n",
      "Epoch: 113 | Training loss: 0.3092798929269172 | Validation loss: 0.4780000038227506 | Accuracy: \t0.90\n",
      "Epoch: 114 | Training loss: 0.31221230423177 | Validation loss: 0.4710984752514245 | Accuracy: \t0.90\n",
      "Epoch: 115 | Training loss: 0.29839391799738807 | Validation loss: 0.476305821943124 | Accuracy: \t0.90\n",
      "Epoch: 116 | Training loss: 0.30664209894703875 | Validation loss: 0.5033014518604167 | Accuracy: \t0.90\n",
      "Epoch: 117 | Training loss: 0.30975209180580315 | Validation loss: 0.48731094387494295 | Accuracy: \t0.90\n",
      "Epoch: 118 | Training loss: 0.3062718525047223 | Validation loss: 0.4862451554090406 | Accuracy: \t0.90\n",
      "Epoch: 119 | Training loss: 0.3046548490541695 | Validation loss: 0.5024520370043547 | Accuracy: \t0.89\n",
      "Epoch: 120 | Training loss: 0.31034737530167333 | Validation loss: 0.46238651570923833 | Accuracy: \t0.89\n",
      "Epoch: 121 | Training loss: 0.2977559911446477 | Validation loss: 0.4798162072971525 | Accuracy: \t0.90\n",
      "Epoch: 122 | Training loss: 0.2975451435858813 | Validation loss: 0.4701129549537926 | Accuracy: \t0.90\n",
      "Epoch: 123 | Training loss: 0.3073959539655103 | Validation loss: 0.45973353949161844 | Accuracy: \t0.90\n",
      "Epoch: 124 | Training loss: 0.305096704376875 | Validation loss: 0.48032821144433296 | Accuracy: \t0.90\n",
      "Epoch: 125 | Training loss: 0.30279778918334915 | Validation loss: 0.4787717769800175 | Accuracy: \t0.89\n",
      "Epoch: 126 | Training loss: 0.30909348047562757 | Validation loss: 0.48758888392522 | Accuracy: \t0.90\n",
      "Epoch: 127 | Training loss: 0.3041066492933924 | Validation loss: 0.4965055887901952 | Accuracy: \t0.89\n",
      "Epoch: 128 | Training loss: 0.29483534179091825 | Validation loss: 0.4954800169302882 | Accuracy: \t0.90\n",
      "Epoch: 129 | Training loss: 0.29956065105260726 | Validation loss: 0.48384926120771576 | Accuracy: \t0.90\n",
      "Epoch: 130 | Training loss: 0.3022924217957774 | Validation loss: 0.48041461300014754 | Accuracy: \t0.90\n",
      "Epoch: 131 | Training loss: 0.29942165486382494 | Validation loss: 0.4772284305821467 | Accuracy: \t0.90\n",
      "Epoch: 132 | Training loss: 0.29481811629718985 | Validation loss: 0.4935113558727468 | Accuracy: \t0.90\n",
      "Epoch: 133 | Training loss: 0.302759831982186 | Validation loss: 0.46813130776418854 | Accuracy: \t0.90\n",
      "Epoch: 134 | Training loss: 0.29594114534051874 | Validation loss: 0.5094781971107034 | Accuracy: \t0.90\n",
      "Epoch: 135 | Training loss: 0.2985338821960565 | Validation loss: 0.49552512188769066 | Accuracy: \t0.90\n",
      "Epoch: 136 | Training loss: 0.3018574372819616 | Validation loss: 0.5120015392659405 | Accuracy: \t0.89\n",
      "Epoch: 137 | Training loss: 0.3002738914288371 | Validation loss: 0.5058928198174102 | Accuracy: \t0.90\n",
      "Epoch: 138 | Training loss: 0.2929142782101417 | Validation loss: 0.4950626507662454 | Accuracy: \t0.90\n",
      "Epoch: 139 | Training loss: 0.29703954054242754 | Validation loss: 0.48503711578545716 | Accuracy: \t0.90\n",
      "Epoch: 140 | Training loss: 0.2983128218693082 | Validation loss: 0.4984713987671802 | Accuracy: \t0.90\n",
      "Epoch: 141 | Training loss: 0.3043210757288371 | Validation loss: 0.4947932199501216 | Accuracy: \t0.90\n",
      "Epoch: 142 | Training loss: 0.2888703347992723 | Validation loss: 0.4962420426775158 | Accuracy: \t0.89\n",
      "Epoch: 143 | Training loss: 0.29205739941910236 | Validation loss: 0.5027626172714774 | Accuracy: \t0.90\n",
      "Epoch: 144 | Training loss: 0.30390669657490427 | Validation loss: 0.4916325598035483 | Accuracy: \t0.90\n",
      "Epoch: 145 | Training loss: 0.29595486800787474 | Validation loss: 0.4812967363897217 | Accuracy: \t0.90\n",
      "Epoch: 146 | Training loss: 0.28718122756642767 | Validation loss: 0.5165060884361967 | Accuracy: \t0.90\n",
      "Epoch: 147 | Training loss: 0.29281544378949903 | Validation loss: 0.4885471051836929 | Accuracy: \t0.90\n",
      "Epoch: 148 | Training loss: 0.2938398969248015 | Validation loss: 0.49488282867329036 | Accuracy: \t0.90\n",
      "Epoch: 149 | Training loss: 0.3046136343876935 | Validation loss: 0.5081528829623502 | Accuracy: \t0.90\n",
      "Epoch: 150 | Training loss: 0.29668970026611907 | Validation loss: 0.4943787391927463 | Accuracy: \t0.90\n",
      "Epoch: 151 | Training loss: 0.296923807309989 | Validation loss: 0.491926828506492 | Accuracy: \t0.91\n",
      "Epoch: 152 | Training loss: 0.2945508094910412 | Validation loss: 0.49715189716535574 | Accuracy: \t0.90\n",
      "Epoch: 153 | Training loss: 0.29973397258983786 | Validation loss: 0.5167504987486011 | Accuracy: \t0.90\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 154 | Training loss: 0.2913617508130476 | Validation loss: 0.5148970357470953 | Accuracy: \t0.90\n",
      "Epoch: 155 | Training loss: 0.294282112995452 | Validation loss: 0.5017424007571668 | Accuracy: \t0.90\n",
      "Epoch: 156 | Training loss: 0.2946350965186627 | Validation loss: 0.4927419950258145 | Accuracy: \t0.90\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-26366830ab8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;31m# clear gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-efec21e8f48a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "label_scores.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "t = F.softmax(label_scores, dim=1)\n",
    "top_p, top_c = t.topk(1, dim=1)\n",
    "print(top_c.flatten())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([6, 9, 9, 9, 6, 9, 9, 6, 9, 5, 9, 6, 6, 0, 6, 0, 9, 1, 6, 9, 9, 6, 6, 9,\n",
      "        6, 6, 6, 9, 1, 9, 0, 9, 6, 0, 9, 9, 6, 6, 9, 9, 5, 9, 6, 9, 7, 9, 6, 9,\n",
      "        9, 9, 6, 6, 6, 9, 8, 9, 9, 6, 9, 9, 9, 9, 6, 9, 9, 6, 9, 6, 6, 9, 9, 0,\n",
      "        6, 6, 9, 6, 9, 1, 0, 9, 9, 6, 1, 9, 6, 6, 9, 6, 9, 9, 9, 6, 9, 9, 6, 9,\n",
      "        2, 6, 4, 7, 6, 1, 9, 9, 9, 9, 7, 9, 6, 9, 9, 1, 9, 6, 6, 6, 8, 6, 9, 9,\n",
      "        6, 6, 2, 6, 9, 9, 6, 6])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([9, 9, 6, 6, 9, 6, 9, 9, 6, 9, 1, 9, 9, 6, 6, 6, 6, 6, 9, 9, 1, 6, 9, 0,\n",
       "        1, 1, 6, 6, 9, 6, 6, 6, 6, 6, 9, 6, 6, 1, 9, 6, 6, 9, 9, 9, 9, 6, 6, 9,\n",
       "        9, 1, 9, 9, 0, 9, 9, 9, 6, 9, 1, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "top_c == y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  ..., False, False,  True],\n",
       "        [ True,  True, False,  ...,  True, False, False],\n",
       "        [ True,  True, False,  ...,  True, False, False],\n",
       "        ...,\n",
       "        [ True,  True, False,  ...,  True, False, False],\n",
       "        [False, False,  True,  ..., False, False,  True],\n",
       "        [False, False,  True,  ..., False, False,  True]])"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "torch.unique((top_c == y).type(torch.FloatTensor), return_counts=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0., 1.]), tensor([4916, 2764]))"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "len(losses)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "figure = plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(len(losses)), losses, label='Training loss')\n",
    "plt.plot(np.arange(len(losses)), validation_losses, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross Entropy Loss')"
      ]
     },
     "metadata": {},
     "execution_count": 139
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "torch.save(model.state_dict(), \"NLPModel_Overfitting\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "testing = sigmoid(label_scores)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "def accuracy(labels, predicted):\n",
    "    total_accuracy = 0\n",
    "    n = len(predicted)\n",
    "    for y, p in zip(labels, predicted):\n",
    "        if (y == p):\n",
    "            total_accuracy +=1\n",
    "    return total_accuracy/n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model v1 = Feature vector standarized and without class weights\n",
    "\n",
    "Model v2 = Feature vector standarized and with class weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (lstm1): LSTM(1041, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "v_test = torch.from_numpy(np.array(x_test, dtype=np.float64)).view(-1, 1, 1041).float().to(device)\n",
    "\n",
    "words_labels = model(v_test) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "words_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.4900, 0.4985, 0.5334,  ..., 0.5728, 0.4702, 0.5405],\n",
       "        [0.5072, 0.4691, 0.5011,  ..., 0.5110, 0.5229, 0.5445],\n",
       "        [0.4387, 0.5019, 0.4730,  ..., 0.4885, 0.4629, 0.5447],\n",
       "        ...,\n",
       "        [0.5095, 0.4933, 0.4889,  ..., 0.5466, 0.5255, 0.4523],\n",
       "        [0.5278, 0.4745, 0.4873,  ..., 0.5408, 0.5146, 0.5460],\n",
       "        [0.5235, 0.4721, 0.5073,  ..., 0.5313, 0.4698, 0.5294]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "words_labels.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([11350, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "y = []\n",
    "\n",
    "for p in words_labels:\n",
    "    i = 0\n",
    "    m = 0\n",
    "    for index, e in enumerate(p):\n",
    "        if float(e) > m:\n",
    "            i = index\n",
    "            m = e\n",
    "    y.append(i+1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "set(y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "print(np.array(y))\n",
    "print(y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 8 10 10 ...  8 10  8]\n",
      "[10 7 7 ... 10 7 10]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "set(y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 9, 10}"
      ]
     },
     "metadata": {},
     "execution_count": 172
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "y = []\n",
    "\n",
    "for p in words_labels:\n",
    "    i = 0\n",
    "    m = 0\n",
    "    for index, e in enumerate(p):\n",
    "        if float(e) > m:\n",
    "            i = index\n",
    "            m = e\n",
    "    y.append(i)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "accuracy(y_test, y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.12140969162995595"
      ]
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "def precision_of(labels, y, of):\n",
    "    n = 0\n",
    "    precision = 0\n",
    "    c = 0\n",
    "    for label, p in zip(labels, y):\n",
    "        if (label == p) and (p == of):\n",
    "            c += 1\n",
    "        if (p == of):\n",
    "            n+=1\n",
    "            \n",
    "    precision = 0 if n==0 else c / n\n",
    "    return precision"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "p0 = precision_of(y_test, y, 0)\n",
    "p1 = precision_of(y_test, y, 1)\n",
    "p2 = precision_of(y_test, y, 2)\n",
    "p3 = precision_of(y_test, y, 3)\n",
    "p4 = precision_of(y_test, y, 4)\n",
    "p5 = precision_of(y_test, y, 5)\n",
    "p6 = precision_of(y_test, y, 6)\n",
    "p7 = precision_of(y_test, y, 7)\n",
    "p8 = precision_of(y_test, y, 8)\n",
    "p9 = precision_of(y_test, y, 9)\n",
    "p10 = precision_of(y_test, y, 10)\n",
    "\n",
    "precision = (p0+p1+p2+p3+p4+p5+p6+p8+p9+p7+p10) / 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "print(precision)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.09914015347161295\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "def recall_of(labels, y, of):\n",
    "    n = 0\n",
    "    recall = 0\n",
    "    c = 0\n",
    "    for label, p in zip(labels, y):\n",
    "        if (label == p) and (p == of):\n",
    "            c += 1\n",
    "        if (label == of):\n",
    "            n+=1\n",
    "            \n",
    "    recall = 0 if n==0 else c / n\n",
    "    return recall"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "p0 = recall_of(y_test, y, 0)\n",
    "p1 = recall_of(y_test, y, 1)\n",
    "p2 = recall_of(y_test, y, 2)\n",
    "p3 = recall_of(y_test, y, 3)\n",
    "p4 = recall_of(y_test, y, 4)\n",
    "p5 = recall_of(y_test, y, 5)\n",
    "p6 = recall_of(y_test, y, 6)\n",
    "p7 = recall_of(y_test, y, 7)\n",
    "p8 = recall_of(y_test, y, 8)\n",
    "p9 = recall_of(y_test, y, 9)\n",
    "p10 = recall_of(y_test, y, 10)\n",
    "\n",
    "recall = (p0+p1+p2+p3+p4+p5+p6+p8+p9+p7+p10) / 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "recall"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.05875414636642144"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}