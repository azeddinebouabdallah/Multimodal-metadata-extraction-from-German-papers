{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "\n",
    "torch.manual_seed(10)\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(20)\n",
    "#model.to(device)\n",
    "#model = BiLSTM(17)\n",
    "\n",
    "\n",
    "# Class weights (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "#weights = torch.tensor([0.69,2.95,0.08,0.02,0.77,0.017,18.59,0 ,0.007,76.83], dtype=torch.float32)\n",
    "#weights = weights / weights.sum()\n",
    "#weights = 1.0 / weights\n",
    "#weights = weights / weights.sum()\n",
    "\n",
    "\n",
    "#loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "#loss_function = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A common headache in this competition is the lack of determinism in the results due to cudnn, the following solves the issue\n",
    "def seed_everything(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vision_output():\n",
    "    i = 1\n",
    "    for file in os.scandir('./vision_output'):\n",
    "        if (os.path.isfile('./nlp_output/{0}'.format(file.name))):\n",
    "            vision_out = []\n",
    "            with open(file, \"rb\") as openfile:\n",
    "                while True:\n",
    "                    try:\n",
    "                        vision_out.append(pickle.load(openfile))\n",
    "                    except EOFError:\n",
    "                        break\n",
    "\n",
    "            processed_out = []\n",
    "\n",
    "            for idk in vision_out:\n",
    "                for segment in idk:\n",
    "                    vector = segment[1]\n",
    "                    for word in segment[0].split(' '):\n",
    "                        processed_out.append([word, vector])\n",
    "\n",
    "            processed_out = processed_out\n",
    "            with open(\"./processed_vision_output/{0}\".format(file.name), 'wb') as f:\n",
    "                pickle.dump(processed_out, f)\n",
    "            print(\"File {0}\".format(i), end='\\r')\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 8817\r"
     ]
    }
   ],
   "source": [
    "process_vision_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input():\n",
    "    i=1\n",
    "    for nlp_file in os.scandir('./nlp_output'):\n",
    "        if not os.path.isfile(\"./processed_vision_output/{0}\".format(nlp_file.name)):\n",
    "            continue\n",
    "        with open(nlp_file, \"rb\") as f:\n",
    "            nlp_out = pickle.load(f)\n",
    "\n",
    "        with open(\"./processed_vision_output/{0}\".format(nlp_file.name), \"rb\") as f:\n",
    "            vision_out = pickle.load(f)\n",
    "        nlp_out = np.reshape(nlp_out, (int(nlp_out.shape[0]/2), -1))\n",
    "        \n",
    "\n",
    "        combined_out = []\n",
    "        clone_nlp_out = np.copy(nlp_out)\n",
    "        for word in vision_out:\n",
    "            if word[0] != '':\n",
    "                match_indexes = np.where(clone_nlp_out == word[0])\n",
    "                if len(match_indexes[0]) == 0:\n",
    "                    continue\n",
    "                match_words = clone_nlp_out[match_indexes[0][0]]\n",
    "                if match_words.shape[0] > 0:\n",
    "                    word_string = match_words[0]\n",
    "                    word_vector = match_words[1]\n",
    "\n",
    "                    combined_out.append([word_string, word_vector, word[1]])\n",
    "                    print(combined_out)\n",
    "                    break\n",
    "                    clone_nlp_out = np.delete(clone_nlp_out, match_indexes[0][0], axis=0)\n",
    "        \n",
    "        break\n",
    "        #with open(\"./input/{0}\".format(nlp_file.name), 'wb') as f:\n",
    "            #pickle.dump(combined_out, f)\n",
    "            #i+=1\n",
    "            #print(i, end='\\r')\n",
    "    print(\"finished {0} files\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LILOG-DB:', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.0121e-05, 1.3362e-05, 1.6208e-05, 3.9565e-05, 2.9993e-05, 9.6917e-06,\n",
      "        1.5591e-05, 7.7356e-05, 9.9926e-01, 5.3165e-04], device='cuda:0')]]\n",
      "finished 1 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-df703234343e>:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  match_indexes = np.where(clone_nlp_out == word[0])\n"
     ]
    }
   ],
   "source": [
    "process_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Racial', array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), tensor([2.0732e-05, 1.5546e-04, 3.6291e-05, 6.5662e-05, 9.9903e-01, 3.6597e-05,\n",
      "        1.9442e-05, 6.5046e-05, 1.5049e-04, 4.1674e-04], device='cuda:0')], ['Enhanced', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['plant', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['fault', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['diagnosis', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['based', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['on', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['of', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['transient', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['stages.', array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1.7972e-04, 6.9671e-05, 2.3943e-04, 4.3705e-04, 2.2131e-04, 4.9830e-05,\n",
      "        6.1091e-05, 1.7892e-04, 9.9815e-01, 4.1133e-04], device='cuda:0')], ['Isaac', array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([3.0564e-04, 1.0721e-03, 2.2984e-04, 9.9682e-01, 2.1688e-04, 4.7626e-05,\n",
      "        9.1904e-05, 1.5589e-04, 7.2150e-04, 3.3961e-04], device='cuda:0')], ['Monroy,', array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([3.0564e-04, 1.0721e-03, 2.2984e-04, 9.9682e-01, 2.1688e-04, 4.7626e-05,\n",
      "        9.1904e-05, 1.5589e-04, 7.2150e-04, 3.3961e-04], device='cuda:0')], ['Ethnic', array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), tensor([1.0286e-04, 1.7300e-04, 4.2152e-04, 5.4416e-04, 2.9929e-04, 1.2524e-04,\n",
      "        1.1383e-04, 9.9524e-01, 8.5586e-04, 2.1214e-03], device='cuda:0')], ['and', array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), tensor([1.0286e-04, 1.7300e-04, 4.2152e-04, 5.4416e-04, 2.9929e-04, 1.2524e-04,\n",
      "        1.1383e-04, 9.9524e-01, 8.5586e-04, 2.1214e-03], device='cuda:0')], ['Studies', array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), tensor([1.0286e-04, 1.7300e-04, 4.2152e-04, 5.4416e-04, 2.9929e-04, 1.2524e-04,\n",
      "        1.1383e-04, 9.9524e-01, 8.5586e-04, 2.1214e-03], device='cuda:0')], ['Mediadesign', array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), tensor([9.2415e-05, 9.9076e-01, 3.3863e-04, 6.1355e-03, 3.3585e-04, 4.2044e-04,\n",
      "        7.7328e-04, 1.9496e-04, 1.8287e-04, 7.6354e-04], device='cuda:0')], ['Hochschule', array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), tensor([9.2415e-05, 9.9076e-01, 3.3863e-04, 6.1355e-03, 3.3585e-04, 4.2044e-04,\n",
      "        7.7328e-04, 1.9496e-04, 1.8287e-04, 7.6354e-04], device='cuda:0')]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./input/11258_1341.pickle\", \"rb\") as f:\n",
    "    vision_out = pickle.load(f)\n",
    "    print(vision_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "labels = []\n",
    "words = []\n",
    "\n",
    "for file in os.scandir('./input'):\n",
    "    with open(file, 'rb') as f:\n",
    "        vs = pickle.load(f)\n",
    "    \n",
    "    for w in vs:\n",
    "        \n",
    "        words.append(w[0])\n",
    "        temp_w = w[2].cpu()\n",
    "        temp_t = temp_w.numpy()\n",
    "        vectors.append(np.concatenate((temp_t, w[1])))\n",
    "        labels.append(np.argmax(w[1]))\n",
    "    \n",
    "vectors = np.array(vectors)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610439, 20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.82922943e-05, 6.14503442e-05, 1.55886766e-04, 1.45714599e-04,\n",
       "       2.01831383e-04, 3.60690901e-05, 4.54061919e-05, 1.10021567e-04,\n",
       "       9.98981655e-01, 1.83759941e-04, 0.00000000e+00, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610439,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(vectors, labels, test_size=0.2, random_state=42,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488351, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488351,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122088, 20)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([488351, 1, 20])\n",
      "torch.Size([488351])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.from_numpy(np.array(y_train, dtype=np.int64)).to(device)\n",
    "v = torch.from_numpy(np.array(x_train, dtype=np.float64)).view(-1, 1, 20).float().to(device)\n",
    "print(v.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([122088, 1, 20])\n",
      "torch.Size([122088])\n"
     ]
    }
   ],
   "source": [
    "labels_2 = torch.from_numpy(np.array(y_test, dtype=np.int64)).to(device)\n",
    "v2 = torch.from_numpy(np.array(x_test, dtype=np.float64)).view(-1, 1, 20).float().to(device)\n",
    "print(v2.shape)\n",
    "print(labels_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.94781554e-01, 1.85067183e-04, 5.69579948e-04, 1.04696129e-03,\n",
       "       1.74202723e-04, 3.27866292e-04, 1.80693227e-04, 1.15335826e-03,\n",
       "       9.47981840e-04, 6.32654235e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset = dataset\n",
    "    def __getitem__(self,index):\n",
    "        data,target = self.dataset[index]\n",
    "        return data,target,index\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset(torch.utils.data.TensorDataset(v, labels))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 128, shuffle=True)\n",
    "\n",
    "test = MyDataset(torch.utils.data.TensorDataset(v2, labels_2))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module): \n",
    "    # This NLP part Will consist of two bidirectional lstm layers and it's output is \n",
    "    # determined by the LSTM's last hidden states or output vectors.\n",
    "\n",
    "    # This will take as an input a sequence of words and output the last hidden layer\n",
    "    # the last hidden states of 2-layer bidirectional LSTM will be the input of the last multimodel network \n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim = 256, layer_dim =2, output_dim = 10):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        \n",
    "        # Replace this when using GPU\n",
    "        #self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.device = 'cpu'\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        #Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim # maybe set this to 256\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building the LSTM \n",
    "        # batch_first = True causes the input/output to be of shape 3D (batch_dim, seq_dim, feature_dim) \n",
    "        # output will be the same dim as the hidden dim\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, layer_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "                \n",
    "        # Initialize hidden state with zeros\n",
    "        # self.layer_dim * 2. because we have one going forwards and another going backwards\n",
    "        #h0 = torch.randn(self.layer_dim * 2, x.size(0), self.hidden_dim, device=self.device)\n",
    "        h0 = torch.randn(self.layer_dim * 2, x.size(0), self.hidden_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialize cell state\n",
    "        #c0 =  torch.randn(self.layer_dim * 2, x.size(0), self.hidden_dim, device=self.device)\n",
    "        c0 =  torch.randn(self.layer_dim * 2, x.size(0), self.hidden_dim)\n",
    "        \n",
    "        # We suppose we are conducting a 28 time steps In case of using \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm1(x, (h0.detach(), c0.detach()))\n",
    "        # out = self.fc(out.view(out.size(0), -1))\n",
    "          \n",
    "        # Without the activation function, out will contain the last hidden layer.\n",
    "        # This could be obtianed from hn[-1] as well.\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        \n",
    "        return out\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 256, 100, 256 if we have (input dim = 100 and hidden dim = 100)\n",
    "        # out[:, -1, :] => 256, 256 --> because we just want the last time step hidden states\n",
    "        #out = out[:, -1, :] # without an activation function\n",
    "\n",
    "        # now our: out.size() --> 256, 10 (if output dimension is equal to 10)\n",
    "        #return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training loss: 0.026181706111704367 | Validation loss: 0.0023265608950266085 | Accuracy: \t1.00\n",
      "Loss decreased: inf ==> 0.0023265608950266085\n",
      "Epoch: 1 | Training loss: 0.0014177623502812104 | Validation loss: 0.0008734723909996461 | Accuracy: \t1.00\n",
      "Loss decreased: 0.0023265608950266085 ==> 0.0008734723909996461\n",
      "Epoch: 2 | Training loss: 0.0012325049343457652 | Validation loss: 0.0009271577457463253 | Accuracy: \t1.00\n",
      "Epoch: 3 | Training loss: 0.0011611079196989554 | Validation loss: 0.0007603225659541713 | Accuracy: \t1.00\n",
      "Loss decreased: 0.0008734723909996461 ==> 0.0007603225659541713\n",
      "Epoch: 4 | Training loss: 0.0013527928674159882 | Validation loss: 0.0006295835991884246 | Accuracy: \t1.00\n",
      "Loss decreased: 0.0007603225659541713 ==> 0.0006295835991884246\n",
      "Epoch: 5 | Training loss: 0.0010729187503587278 | Validation loss: 0.0010386237547610107 | Accuracy: \t1.00\n",
      "Epoch: 6 | Training loss: 0.0012260115481817215 | Validation loss: 0.0012125206643060404 | Accuracy: \t1.00\n",
      "Epoch: 7 | Training loss: 0.0012659218518428104 | Validation loss: 0.001183000106805106 | Accuracy: \t1.00\n",
      "Epoch: 8 | Training loss: 0.0013360363343181913 | Validation loss: 0.0015559813442263268 | Accuracy: \t1.00\n",
      "Epoch: 9 | Training loss: 0.001253533125648198 | Validation loss: 0.0006980189511666356 | Accuracy: \t1.00\n",
      "Epoch: 10 | Training loss: 0.0013533682624243938 | Validation loss: 0.0012060821498796426 | Accuracy: \t1.00\n",
      "Epoch: 11 | Training loss: 0.0013857309564999265 | Validation loss: 0.0007052892989427067 | Accuracy: \t1.00\n",
      "Epoch: 12 | Training loss: 0.0011135415771146263 | Validation loss: 0.00042999106178903316 | Accuracy: \t1.00\n",
      "Loss decreased: 0.0006295835991884246 ==> 0.00042999106178903316\n",
      "Epoch: 13 | Training loss: 0.0012957102178069815 | Validation loss: 0.0007966486371280422 | Accuracy: \t1.00\n",
      "Epoch: 14 | Training loss: 0.001539549165016548 | Validation loss: 0.0005575380607268742 | Accuracy: \t1.00\n",
      "Epoch: 15 | Training loss: 0.0014622306410871579 | Validation loss: 0.000602654075370215 | Accuracy: \t1.00\n",
      "Epoch: 16 | Training loss: 0.0010369204187881177 | Validation loss: 0.0008820695846894548 | Accuracy: \t1.00\n",
      "Epoch: 17 | Training loss: 0.001435035658780111 | Validation loss: 0.0013217007881253585 | Accuracy: \t1.00\n",
      "Epoch: 18 | Training loss: 0.001281973179121097 | Validation loss: 0.0007012814152541876 | Accuracy: \t1.00\n",
      "Epoch: 19 | Training loss: 0.0009214437520954651 | Validation loss: 0.0009032067032146891 | Accuracy: \t1.00\n",
      "Epoch: 20 | Training loss: 0.0012303942812345145 | Validation loss: 0.0004475589650162924 | Accuracy: \t1.00\n",
      "Epoch: 21 | Training loss: 0.001016906917569029 | Validation loss: 0.0004649006413846663 | Accuracy: \t1.00\n",
      "Epoch: 22 | Training loss: 0.001166252974329582 | Validation loss: 0.0008641980181426095 | Accuracy: \t1.00\n",
      "Epoch: 23 | Training loss: 0.0009640223967994253 | Validation loss: 0.00048145029321758863 | Accuracy: \t1.00\n",
      "Epoch: 24 | Training loss: 0.0011266934783249868 | Validation loss: 0.001326348308746112 | Accuracy: \t1.00\n",
      "Epoch: 25 | Training loss: 0.0015199984443400088 | Validation loss: 0.0009610674344760733 | Accuracy: \t1.00\n",
      "Epoch: 26 | Training loss: 0.0013543665547838942 | Validation loss: 0.0007223811757950415 | Accuracy: \t1.00\n",
      "Epoch: 27 | Training loss: 0.0009935166556569656 | Validation loss: 0.000866508542601759 | Accuracy: \t1.00\n",
      "Epoch: 28 | Training loss: 0.0013935874818864927 | Validation loss: 0.0006183758405690679 | Accuracy: \t1.00\n",
      "Epoch: 29 | Training loss: 0.0013040901988246683 | Validation loss: 0.0004257764678426328 | Accuracy: \t1.00\n",
      "Loss decreased: 0.00042999106178903316 ==> 0.0004257764678426328\n",
      "Epoch: 30 | Training loss: 0.0009344209390954175 | Validation loss: 0.0007943494704420186 | Accuracy: \t1.00\n",
      "Epoch: 31 | Training loss: 0.0010425470121746291 | Validation loss: 0.0007090448709795132 | Accuracy: \t1.00\n",
      "Epoch: 32 | Training loss: 0.0009560381895463471 | Validation loss: 0.0008744691968909946 | Accuracy: \t1.00\n",
      "Epoch: 33 | Training loss: 0.0011648448922779236 | Validation loss: 0.00065253877130175 | Accuracy: \t1.00\n",
      "Epoch: 34 | Training loss: 0.0012496518053514473 | Validation loss: 0.0009733971261575154 | Accuracy: \t1.00\n",
      "Epoch: 35 | Training loss: 0.0011452592183873833 | Validation loss: 0.000685388620339576 | Accuracy: \t1.00\n",
      "Epoch: 36 | Training loss: 0.0014134466064462158 | Validation loss: 0.000970482960791721 | Accuracy: \t1.00\n",
      "Epoch: 37 | Training loss: 0.0012944165902768479 | Validation loss: 0.00020723291306254163 | Accuracy: \t1.00\n",
      "Loss decreased: 0.0004257764678426328 ==> 0.00020723291306254163\n",
      "Epoch: 38 | Training loss: 0.0013197650473556978 | Validation loss: 0.0005027404119143538 | Accuracy: \t1.00\n",
      "Epoch: 39 | Training loss: 0.0010577770491178896 | Validation loss: 0.0004915454544305688 | Accuracy: \t1.00\n",
      "Epoch: 40 | Training loss: 0.0010795948078426026 | Validation loss: 0.00045526672984258173 | Accuracy: \t1.00\n",
      "Epoch: 41 | Training loss: 0.0011343833374246935 | Validation loss: 0.0006529636211285363 | Accuracy: \t1.00\n",
      "Epoch: 42 | Training loss: 0.0010734161563149024 | Validation loss: 0.00072353237643048 | Accuracy: \t1.00\n",
      "Epoch: 43 | Training loss: 0.0010663918053003922 | Validation loss: 0.000746689027748997 | Accuracy: \t1.00\n",
      "Epoch: 44 | Training loss: 0.0009795515829327808 | Validation loss: 0.0005826608798637023 | Accuracy: \t1.00\n",
      "Epoch: 45 | Training loss: 0.0008316598816439135 | Validation loss: 0.0011145330940340475 | Accuracy: \t1.00\n",
      "Epoch: 46 | Training loss: 0.0010154769913678515 | Validation loss: 0.0005691120544523434 | Accuracy: \t1.00\n",
      "Epoch: 47 | Training loss: 0.0013909262359686693 | Validation loss: 0.0004532521037988755 | Accuracy: \t1.00\n",
      "Epoch: 48 | Training loss: 0.0009297024978168547 | Validation loss: 0.00042111770304947664 | Accuracy: \t1.00\n",
      "Epoch: 49 | Training loss: 0.0008457276558250023 | Validation loss: 0.00040031719983965743 | Accuracy: \t1.00\n",
      "Epoch: 50 | Training loss: 0.0007775178964531847 | Validation loss: 0.0009378882905438031 | Accuracy: \t1.00\n",
      "Epoch: 51 | Training loss: 0.0011995750075694761 | Validation loss: 0.0011478218061832847 | Accuracy: \t1.00\n",
      "Epoch: 52 | Training loss: 0.0009021662402052396 | Validation loss: 0.001309538259568837 | Accuracy: \t1.00\n",
      "Epoch: 53 | Training loss: 0.0008763773448558148 | Validation loss: 0.0013053242705117647 | Accuracy: \t1.00\n",
      "Epoch: 54 | Training loss: 0.0008413589737395294 | Validation loss: 0.0005816819612479523 | Accuracy: \t1.00\n",
      "Epoch: 55 | Training loss: 0.0009096290707658403 | Validation loss: 0.0007607932576784081 | Accuracy: \t1.00\n",
      "Epoch: 56 | Training loss: 0.0013234518320076904 | Validation loss: 0.0006587036912772203 | Accuracy: \t1.00\n",
      "Epoch: 57 | Training loss: 0.0008640312915684997 | Validation loss: 0.0005990101641306838 | Accuracy: \t1.00\n",
      "Epoch: 58 | Training loss: 0.0011110919721695344 | Validation loss: 0.0008034482852906944 | Accuracy: \t1.00\n",
      "Epoch: 59 | Training loss: 0.0009802514665407168 | Validation loss: 0.0011537819638546842 | Accuracy: \t1.00\n",
      "Epoch: 60 | Training loss: 0.001097170124364296 | Validation loss: 0.00043403444254477516 | Accuracy: \t1.00\n",
      "Epoch: 61 | Training loss: 0.0008226600384940047 | Validation loss: 0.0002472699914546962 | Accuracy: \t1.00\n",
      "Epoch: 62 | Training loss: 0.0007759489918416759 | Validation loss: 0.000792342796059727 | Accuracy: \t1.00\n",
      "Epoch: 63 | Training loss: 0.0009297934587580044 | Validation loss: 0.0008941908468595917 | Accuracy: \t1.00\n",
      "Epoch: 64 | Training loss: 0.0009464215867208322 | Validation loss: 0.0008296484541612209 | Accuracy: \t1.00\n",
      "Epoch: 65 | Training loss: 0.0011705118258321556 | Validation loss: 0.0012156724821594579 | Accuracy: \t1.00\n",
      "Epoch: 66 | Training loss: 0.0009942007098320486 | Validation loss: 0.0007060663688668686 | Accuracy: \t1.00\n",
      "Epoch: 67 | Training loss: 0.0011040961339398676 | Validation loss: 0.0009525577961754488 | Accuracy: \t1.00\n",
      "Epoch: 68 | Training loss: 0.0011461059624708438 | Validation loss: 0.000607179000824201 | Accuracy: \t1.00\n",
      "Epoch: 69 | Training loss: 0.0011276681382464896 | Validation loss: 0.000730979677497638 | Accuracy: \t1.00\n",
      "Epoch: 70 | Training loss: 0.0011116841883072454 | Validation loss: 0.0006414724216109825 | Accuracy: \t1.00\n",
      "Epoch: 71 | Training loss: 0.0008784394145866474 | Validation loss: 0.0006151302008024777 | Accuracy: \t1.00\n",
      "Epoch: 72 | Training loss: 0.0008161583055693739 | Validation loss: 0.0005628365796464274 | Accuracy: \t1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 | Training loss: 0.0011239066900261942 | Validation loss: 0.00017161035257002113 | Accuracy: \t1.00\n",
      "Loss decreased: 0.00020723291306254163 ==> 0.00017161035257002113\n",
      "Epoch: 74 | Training loss: 0.0009780213689529335 | Validation loss: 0.0002735201206322085 | Accuracy: \t1.00\n",
      "Epoch: 75 | Training loss: 0.0010437553369975101 | Validation loss: 0.0007498090972361447 | Accuracy: \t1.00\n",
      "Epoch: 76 | Training loss: 0.0011295732956889534 | Validation loss: 0.0005200856886175248 | Accuracy: \t1.00\n",
      "Epoch: 77 | Training loss: 0.0010049681002744118 | Validation loss: 0.0005379448357618973 | Accuracy: \t1.00\n",
      "Epoch: 78 | Training loss: 0.0008826214021777965 | Validation loss: 0.0005658819214304766 | Accuracy: \t1.00\n",
      "Epoch: 79 | Training loss: 0.0008552117953983181 | Validation loss: 0.0006589638375090363 | Accuracy: \t1.00\n",
      "Epoch: 80 | Training loss: 0.0007645260116135712 | Validation loss: 0.00024232503597708128 | Accuracy: \t1.00\n",
      "Epoch: 81 | Training loss: 0.0005323662215165068 | Validation loss: 0.00019777786932506552 | Accuracy: \t1.00\n",
      "Epoch: 82 | Training loss: 0.0010314062175931155 | Validation loss: 0.0007263324809620561 | Accuracy: \t1.00\n",
      "Epoch: 83 | Training loss: 0.001048154027668698 | Validation loss: 0.000282187031081433 | Accuracy: \t1.00\n",
      "Epoch: 84 | Training loss: 0.0008222011732456559 | Validation loss: 0.00014503217596298977 | Accuracy: \t1.00\n",
      "Loss decreased: 0.00017161035257002113 ==> 0.00014503217596298977\n",
      "Epoch: 85 | Training loss: 0.0008671561420993898 | Validation loss: 0.0001368948200025585 | Accuracy: \t1.00\n",
      "Loss decreased: 0.00014503217596298977 ==> 0.0001368948200025585\n",
      "Epoch: 86 | Training loss: 0.0009914342146774148 | Validation loss: 0.00022766291679723508 | Accuracy: \t1.00\n",
      "Epoch: 87 | Training loss: 0.0008317618835863662 | Validation loss: 0.0003757883940125403 | Accuracy: \t1.00\n",
      "Epoch: 88 | Training loss: 0.0006479616567027156 | Validation loss: 0.0007240046481149197 | Accuracy: \t1.00\n",
      "Epoch: 89 | Training loss: 0.001023499638572378 | Validation loss: 0.0006175517863587697 | Accuracy: \t1.00\n",
      "Epoch: 90 | Training loss: 0.0010577848649730307 | Validation loss: 0.0005043728442776461 | Accuracy: \t1.00\n",
      "Epoch: 91 | Training loss: 0.0008399800512542575 | Validation loss: 0.0004048807201524643 | Accuracy: \t1.00\n",
      "Epoch: 92 | Training loss: 0.0009254885325822796 | Validation loss: 0.001171478529456837 | Accuracy: \t1.00\n",
      "Epoch: 93 | Training loss: 0.0008612759940170905 | Validation loss: 0.0010325432983074546 | Accuracy: \t1.00\n",
      "Epoch: 94 | Training loss: 0.0010296937343431437 | Validation loss: 0.0003107517748031316 | Accuracy: \t1.00\n",
      "Epoch: 95 | Training loss: 0.0006242972715806563 | Validation loss: 0.00041202935901394987 | Accuracy: \t1.00\n",
      "Epoch: 96 | Training loss: 0.0007547263373324253 | Validation loss: 0.0006760928818207373 | Accuracy: \t1.00\n",
      "Epoch: 97 | Training loss: 0.0010288471587140242 | Validation loss: 0.0008521261797948599 | Accuracy: \t1.00\n",
      "Epoch: 98 | Training loss: 0.0008038443894694718 | Validation loss: 0.0005853388890099292 | Accuracy: \t1.00\n",
      "Epoch: 99 | Training loss: 0.0006203655947410113 | Validation loss: 0.001224297620235189 | Accuracy: \t1.00\n",
      "Epoch: 100 | Training loss: 0.000741231440696394 | Validation loss: 0.0003963904440801513 | Accuracy: \t1.00\n",
      "Epoch: 101 | Training loss: 0.0008920111151068218 | Validation loss: 0.00013565925957200112 | Accuracy: \t1.00\n",
      "Loss decreased: 0.0001368948200025585 ==> 0.00013565925957200112\n",
      "Epoch: 102 | Training loss: 0.0007986126780783877 | Validation loss: 0.0004918261740752198 | Accuracy: \t1.00\n",
      "Epoch: 103 | Training loss: 0.0007532315177245429 | Validation loss: 0.0005623297666688617 | Accuracy: \t1.00\n",
      "Epoch: 104 | Training loss: 0.0006945018167097818 | Validation loss: 0.0005116176712451444 | Accuracy: \t1.00\n",
      "Epoch: 105 | Training loss: 0.0008452591457516908 | Validation loss: 0.0004271618614536936 | Accuracy: \t1.00\n",
      "Epoch: 106 | Training loss: 0.0006464923764737824 | Validation loss: 0.00027415543934830057 | Accuracy: \t1.00\n",
      "Epoch: 107 | Training loss: 0.000942023568534643 | Validation loss: 0.0006740767287777314 | Accuracy: \t1.00\n",
      "Epoch: 108 | Training loss: 0.0006536052525890404 | Validation loss: 0.0007717320391746295 | Accuracy: \t1.00\n",
      "Epoch: 109 | Training loss: 0.0005711921312964862 | Validation loss: 0.0007005250138018186 | Accuracy: \t1.00\n",
      "Epoch: 110 | Training loss: 0.0006803358700703147 | Validation loss: 0.00014671601601575488 | Accuracy: \t1.00\n",
      "Epoch: 111 | Training loss: 0.0009180061019510998 | Validation loss: 0.00012101815111443572 | Accuracy: \t1.00\n",
      "Loss decreased: 0.00013565925957200112 ==> 0.00012101815111443572\n",
      "Epoch: 112 | Training loss: 0.0009036250475912433 | Validation loss: 0.0008705825816456589 | Accuracy: \t1.00\n",
      "Epoch: 113 | Training loss: 0.0006660664202524182 | Validation loss: 0.0004394200471684833 | Accuracy: \t1.00\n",
      "Epoch: 114 | Training loss: 0.0008552457288690346 | Validation loss: 0.0005600470086652737 | Accuracy: \t1.00\n",
      "Epoch: 115 | Training loss: 0.0007156981659282439 | Validation loss: 0.0005597553464268342 | Accuracy: \t1.00\n",
      "Epoch: 116 | Training loss: 0.0008623240016239043 | Validation loss: 0.0007663414970316692 | Accuracy: \t1.00\n",
      "Epoch: 117 | Training loss: 0.0008854959098057529 | Validation loss: 0.0004650680993380718 | Accuracy: \t1.00\n",
      "Epoch: 118 | Training loss: 0.0006489027061599543 | Validation loss: 0.000340457208593768 | Accuracy: \t1.00\n",
      "Epoch: 119 | Training loss: 0.0008295606192066363 | Validation loss: 0.0006182161566213015 | Accuracy: \t1.00\n",
      "Epoch: 120 | Training loss: 0.0005725016848090326 | Validation loss: 0.0004721043113131468 | Accuracy: \t1.00\n",
      "Epoch: 121 | Training loss: 0.0009651759456778464 | Validation loss: 0.0005468715263280221 | Accuracy: \t1.00\n",
      "Epoch: 122 | Training loss: 0.0007808202052675004 | Validation loss: 0.0002892947431690493 | Accuracy: \t1.00\n",
      "Epoch: 123 | Training loss: 0.0011037260788739952 | Validation loss: 0.0007936789491734998 | Accuracy: \t1.00\n",
      "Epoch: 124 | Training loss: 0.0007260690255176598 | Validation loss: 0.0007234205452401622 | Accuracy: \t1.00\n",
      "Epoch: 125 | Training loss: 0.0005306925086396735 | Validation loss: 0.00027809147751884386 | Accuracy: \t1.00\n",
      "Epoch: 126 | Training loss: 0.0007423265059431375 | Validation loss: 0.000540920146044004 | Accuracy: \t1.00\n",
      "Epoch: 127 | Training loss: 0.0005977694800269072 | Validation loss: 0.0005322490645848328 | Accuracy: \t1.00\n",
      "Epoch: 128 | Training loss: 0.0008648534849666238 | Validation loss: 0.0003575575179546663 | Accuracy: \t1.00\n",
      "Epoch: 129 | Training loss: 0.0005101754428105558 | Validation loss: 0.00027024881040323584 | Accuracy: \t1.00\n",
      "Epoch: 130 | Training loss: 0.0006842959270360338 | Validation loss: 0.0005911736256989826 | Accuracy: \t1.00\n",
      "Epoch: 131 | Training loss: 0.0008012298301856617 | Validation loss: 0.0005359198948962772 | Accuracy: \t1.00\n",
      "Epoch: 132 | Training loss: 0.0006028291323811282 | Validation loss: 0.00032835636923682614 | Accuracy: \t1.00\n",
      "Epoch: 133 | Training loss: 0.0007195706772244952 | Validation loss: 0.0003813338374216435 | Accuracy: \t1.00\n",
      "Epoch: 134 | Training loss: 0.0012773102104814036 | Validation loss: 0.0002343541386832236 | Accuracy: \t1.00\n",
      "Epoch: 135 | Training loss: 0.0006884343638473196 | Validation loss: 0.0007031559519406322 | Accuracy: \t1.00\n",
      "Epoch: 136 | Training loss: 0.0006600616661618645 | Validation loss: 0.00020858735717756586 | Accuracy: \t1.00\n",
      "Epoch: 137 | Training loss: 0.0009475282051309467 | Validation loss: 0.0008971360869605741 | Accuracy: \t1.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-33ea3cc84908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlabel_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Calculate loss, backpropagate, and update weights/parameters by calling opt.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-eb46f35925b8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# We need to detach as we are doing truncated backpropagation through time (BPTT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# If we don't, we'll backprop all the way to the start even after going through another batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;31m# out = self.fc(out.view(out.size(0), -1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BiLSTM(20)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "\n",
    "# Training the model\n",
    "batch_size = 128\n",
    "epochs = 300\n",
    "losses = []\n",
    "validation_losses = []\n",
    "min_loss = np.Inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i, (x_batch, y_batch, index) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        label_scores = model(x_batch)\n",
    "        # Calculate loss, backpropagate, and update weights/parameters by calling opt.step()\n",
    "        loss = criterion(label_scores, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*x_batch.size(0)\n",
    "    \n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    losses.append(train_loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        accuracy = 0\n",
    "        model.eval()\n",
    "        for x, y, i in test_loader:\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            val_loss += loss.item()*x.size(0)\n",
    "            \n",
    "            scores, classes = F.softmax(out, dim=1).topk(1, dim=1)\n",
    "            equals = classes == y.view(*classes.shape)\n",
    "            \n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "            \n",
    "        val_loss = val_loss/len(test_loader.sampler)\n",
    "        accuracy = accuracy/len(test_loader)\n",
    "            \n",
    "    validation_losses.append(val_loss)\n",
    "    print(\"Epoch: {0} | Training loss: {1} | Validation loss: {2} | Accuracy: \\t{3:.2f}\".format(epoch, train_loss, val_loss, accuracy))\n",
    "    \n",
    "    if (val_loss < min_loss):\n",
    "        torch.save(model.state_dict(), \"model_fixed_v1.pt\")\n",
    "        print(\"Loss decreased: {0} ==> {1}\".format(min_loss, val_loss))\n",
    "        min_loss = val_loss\n",
    "    \n",
    "print(\"Bi-LSTM model training is done!                           \", end='\\r')\n",
    "print(\"final labels {0}\".format(label_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"FinalModelOverfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross Entropy Loss')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "figure = plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(len(losses)), losses, label='Training loss')\n",
    "plt.plot(np.arange(len(losses)), validation_losses, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 378982,\n",
       "         0: 33159,\n",
       "         1: 44129,\n",
       "         4: 9474,\n",
       "         2: 8678,\n",
       "         9: 12649,\n",
       "         3: 518,\n",
       "         8: 283,\n",
       "         5: 449,\n",
       "         7: 30})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6, device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8c7a1f0ecbd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'label_scores' is not defined"
     ]
    }
   ],
   "source": [
    "label_scores[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (lstm1): LSTM(20, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (Sigmoid): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"FinalModelV2\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predicted):\n",
    "    total_accuracy = 0\n",
    "    n = len(predicted)\n",
    "    for y, p in zip(labels, predicted):\n",
    "        if (y == p):\n",
    "            total_accuracy +=1\n",
    "    return total_accuracy/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_test = torch.from_numpy(np.array(x_train, dtype=np.float64)).view(-1, 1, 20).float()\n",
    "predicted = model(v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "for p in predicted:\n",
    "    i = 0\n",
    "    m = 0\n",
    "    for index, e in enumerate(p):\n",
    "        if float(e) > m:\n",
    "            i = index\n",
    "            m = e\n",
    "    y.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 27647,\n",
       "         9: 60323,\n",
       "         7: 21769,\n",
       "         10: 48768,\n",
       "         6: 78758,\n",
       "         5: 64879,\n",
       "         1: 70385,\n",
       "         3: 33409,\n",
       "         8: 54048,\n",
       "         4: 28365})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03611336927742546\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(y_test, y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
